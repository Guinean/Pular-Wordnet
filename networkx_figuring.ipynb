{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in c:\\users\\peter\\vsc-workspace_pular\\.pular_venv\\lib\\site-packages (2.6.3)\n",
      "Requirement already satisfied: inspectshow in c:\\users\\peter\\vsc-workspace_pular\\.pular_venv\\lib\\site-packages (1.2)\n",
      "Requirement already satisfied: tree-inspector in c:\\users\\peter\\vsc-workspace_pular\\.pular_venv\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\peter\\vsc-workspace_pular\\.pular_venv\\lib\\site-packages (from tree-inspector) (1.21.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\peter\\vsc-workspace_pular\\.pular_venv\\lib\\site-packages (from tree-inspector) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\peter\\vsc-workspace_pular\\.pular_venv\\lib\\site-packages (from jinja2->tree-inspector) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "# ! pip install networkx\n",
    "# ! pip install inspectshow\n",
    "# ! pip install tree-inspector\n",
    "import inspectshow\n",
    "import tree_inspector\n",
    "import inspect\n",
    "import types\n",
    "import docx\n",
    "from docx import Document\n",
    "import networkx as nx\n",
    "import pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, List, Any, Union, Tuple\n",
    "import pydantic\n",
    "from pydantic import ValidationError, validator, root_validator, Field, constr\n",
    "from pydantic_docx import Docx_Paragraph_and_Runs, read_docx #type:ignore\n",
    "from pydantic_docx_processor import create_sized_dataframe, expand_dataframe #type:ignore\n",
    "import re\n",
    "import json\n",
    "from itertools import compress, chain\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_element': <CT_P '<w:p>' at 0x1fb9915b4a8>, '_p': <CT_P '<w:p>' at 0x1fb9915b4a8>, '_parent': <docx.document._Body object at 0x000001FB991506C8>, 'alignment': None, 'paragraph_format': <docx.text.parfmt.ParagraphFormat object at 0x000001FB99150CC8>, 'part': <docx.parts.document.DocumentPart object at 0x000001FB97A83B08>, 'runs': [<docx.text.run.Run object at 0x000001FB99150E88>, <docx.text.run.Run object at 0x000001FB99150EC8>, <docx.text.run.Run object at 0x000001FB99150F08>, <docx.text.run.Run object at 0x000001FB99150448>, <docx.text.run.Run object at 0x000001FB99150348>], 'style': _ParagraphStyle('Normal') id: 2180116713032, 'text': 'a  prn,sbj,sf  DFZH  Z<->'}\n",
      "{'_element': <CT_P '<w:p>' at 0x1fb9915b4f8>, '_p': <CT_P '<w:p>' at 0x1fb9915b4f8>, '_parent': <docx.document._Body object at 0x000001FB991506C8>, 'alignment': None, 'paragraph_format': <docx.text.parfmt.ParagraphFormat object at 0x000001FB97A7B308>, 'part': <docx.parts.document.DocumentPart object at 0x000001FB97A83B08>, 'runs': [<docx.text.run.Run object at 0x000001FB97336808>], 'style': _ParagraphStyle('Normal') id: 2180116710920, 'text': 'you (sg.)'}\n",
      "{'_element': <CT_P '<w:p>' at 0x1fb9915b548>, '_p': <CT_P '<w:p>' at 0x1fb9915b548>, '_parent': <docx.document._Body object at 0x000001FB991506C8>, 'alignment': None, 'paragraph_format': <docx.text.parfmt.ParagraphFormat object at 0x000001FB99150A08>, 'part': <docx.parts.document.DocumentPart object at 0x000001FB97A83B08>, 'runs': [<docx.text.run.Run object at 0x000001FB99150A48>], 'style': _ParagraphStyle('Normal') id: 2180116711048, 'text': 'tu'}\n"
     ]
    }
   ],
   "source": [
    "docx_filename = \"pasted_docx page 1.docx\"\n",
    "\n",
    "document = Document(docx_filename)\n",
    "\n",
    "\n",
    "# def isdataclass(obj):\n",
    "#    return type(obj)==type\n",
    "for p in document.paragraphs[4:7]:\n",
    "   methods = inspect.getmembers(p,inspect.ismethod)\n",
    "   # funcs = inspect.getmembers(p,inspect.isfunction)\n",
    "   # classes = inspect.getmembers(p,inspect.isclass)\n",
    "   # modules = inspect.getmembers(p,inspect.ismodule)\n",
    "   # dataclasses = inspect.getmembers(p,isdataclass)\n",
    "   # print(dataclasses)\n",
    "   # builin = inspect.getmembers(p,inspect.isbuiltin)\n",
    "   # builtin = ['']\n",
    "   all_mems = inspect.getmembers(p)\n",
    "   # print(len(i))\n",
    "   # print(i[5:10])\n",
    "   # print(type(i[1][1]))\n",
    "   # names = [m[0] for m in i]\n",
    "   # print(names)\n",
    "   # print(i)\n",
    "   # break\n",
    "   dct = {'methods':methods,'all_mems':all_mems}\n",
    "   # names = {k:[m[0] for m in v] for k,v in dct.items()}\n",
    "   # dct['all_mems'] = [m for m in dct['all_mems'] if not any([m in dct['methods'],m in dct['funcs'],m in dct['classes']]) ]\n",
    "   # for k,v in dct.items():\n",
    "   # names = {k:[m[0] for m in v] for k,v in dct.items()}\n",
    "   # # print(names)\n",
    "   dirs = {k:v for k,v in all_mems if  not k.startswith('__') and (k,v) not in methods}\n",
    "   # dirs = {k:v for k,v in all_mems if  not k.startswith('__')}\n",
    "   # print(all_mems)\n",
    "   #  and isinstance(v,object)\n",
    "   print(dirs)\n",
    "   # print(dct['all_mems'])\n",
    "   # print(type(dirs['add_run']))\n",
    "   # print(dir(dirs['_p']))\n",
    "   # print(classes)\n",
    "   # print(dirs['part'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = document.paragraphs[4].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'networkx.classes.digraph.DiGraph'>\n",
      "[('here', {'name': 'me'})]\n"
     ]
    }
   ],
   "source": [
    "from os import name\n",
    "from types import FunctionType\n",
    "from networkx.classes.graph import Graph\n",
    "from docx.text.run import Run\n",
    "\n",
    "def find_node(gr, att, val):\n",
    "    return any([node for node in G.nodes(data=True) if node[1][att] == val])\n",
    "\n",
    "def walk_directory(G:Graph,obj_node, filter_func:FunctionType):\n",
    "   assert(G.has_node(obj_node)), \"passed object is not a node in the graph\"\n",
    "   directory = dir(obj_node)\n",
    "G=nx.DiGraph()\n",
    "print(type(G))\n",
    "G.add_node('here',name='i am me')\n",
    "# print(G.nodes(name=True))\n",
    "G.add_node('here',name='me')\n",
    "print(G.nodes(data=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr = tree_inspector.TreeBuilder(para)\n",
    "# # tree_inspector.\n",
    "# from tree_inspector import dump_tree_to_file\n",
    "\n",
    "# dump_tree_to_file(tr, 'outputTree.html', name='Optional Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('feature_Frames_and_Indexes.pkl', 'rb') as file:\n",
    "    # Call load method to deserialze\n",
    "    output = pickle.load(file, encoding='utf-8')\n",
    "(\n",
    "parsed_object_list, #:List[Tuple[int,Docx_Paragraph_and_Runs]]\n",
    "parsed_object_lookup, #:Dict[int,Docx_Paragraph_and_Runs] = dict(parsed_object_list)\n",
    "doc_para_count, #: int = int(parsed_to_dict['total_encountered_paragraphs']) #type: ignore\n",
    "char_counts, #: Counter = parsed_to_dict['char_counts'] #type: ignore\n",
    "rootFrame,#:pd.DataFrame\n",
    "rootsubpieceFrame, #:pd.DataFrame\n",
    "lemmaFrame, #:pd.DataFrame\n",
    "nonentityParaFrame, #pd.DataFrame\n",
    "cleanerOutcomesDf #pd.DataFrame\n",
    "    ) = output\n",
    "paratext_lookup = {k:v.interogate__para_text() for k,v in parsed_object_lookup.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'networkx.classes.digraph.DiGraph'>\n",
      "[(frozenEntry(entry=Docx_Paragraph_and_Runs(run_italic=[None, True, None], run_bold=[True, None, None], para_first_line_indent=-91440, run_font_name=['TmsRmn 10pt', 'TmsRmn 10pt', 'Helv 8pt'], para_text='a  prn,sbj,sf  DFZH  Z<->', paragraph_enumeration=5, run_font_size_pt=[None, None, 8.0], run_text=['a  ', 'prn,sbj,sf  ', 'DFZH  Z<->'], para_left_indent=73741788000)), {'name': 'i am me'}), ('meme', {'entry': Docx_Paragraph_and_Runs(run_italic=[None, True, None], run_bold=[True, None, None], para_first_line_indent=-91440, run_font_name=['TmsRmn 10pt', 'TmsRmn 10pt', 'Helv 8pt'], para_text='a  prn,sbj,sf  DFZH  Z<->', paragraph_enumeration=5, run_font_size_pt=[None, None, 8.0], run_text=['a  ', 'prn,sbj,sf  ', 'DFZH  Z<->'], para_left_indent=116128800)})]\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from dataclasses import dataclass\n",
    "\n",
    "para = parsed_object_list[1][1].copy()\n",
    "# G=nx.DiGraph()\n",
    "# print(type(G))\n",
    "# G.add_node(para,name='i am me')\n",
    "# # print(G.nodes(name=True))\n",
    "# # G.add_node('here',name='me')\n",
    "# print(G.nodes(data=True))\n",
    "# para.Config.frozen = True\n",
    "\n",
    "# para.__config__.frozen=True\n",
    "# @dataclass(frozen=True,eq=True)\n",
    "class frozenEntry(BaseModel):\n",
    "   entry: Docx_Paragraph_and_Runs\n",
    "\n",
    "   class Config:\n",
    "      frozen = True\n",
    "   def __hash__(self):\n",
    "      return hash(repr(self))\n",
    "\n",
    "try:\n",
    "    froz = frozenEntry(entry=para)\n",
    "except ValidationError as e:\n",
    "    print(e)\n",
    "# dir(froz.entry)\n",
    "# froz.entry.para_first_line_indent=2\n",
    "# print(para)\n",
    "# setattr(para,'para_first_line_indent',2)\n",
    "# para.modify_run_lists(drop_runs=[1])\n",
    "# print(para)\n",
    "hash(froz)\n",
    "# para\n",
    "# hash(repr(froz))\n",
    "G=nx.DiGraph()\n",
    "print(type(G))\n",
    "G.add_node(froz,name='i am me')\n",
    "G.add_node('meme',entry=para)\n",
    "# print(G.nodes(name=True))\n",
    "# G.add_node('here',name='me')\n",
    "print(G.nodes(data=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 ('.pular_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "923e031a042b0333d984d7caca79dafbd2f9b4aa22c38d0c8e773771fd0f73dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
