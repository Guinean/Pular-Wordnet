{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "intention = '''Create an easy/safe API to parse/hold/yield constructions of pydantic docx class objects.\n",
    "In theory this can be generalized and abstracted since the classes are largely absracted. \n",
    "However since this is API based, I will just focus on solutions for THIS dictionary task. These can be expanded later, or just have other APIs added\n",
    "Final objective is have a tool to pass complex commands/instructions, and have it yield a pandas dataframe of the results.\n",
    "Intermediate steps may be yield a list of lists\n",
    "I am not yet sure if there is benefit trying to have the whole dictionary in one notional object. \n",
    "I don't think so, since each operation is psuedo atomic, and any aggregate actions are intended to be done in something like pandas.\n",
    "Eventually I would want a loop for pandas operations to easily feed updates to the data. \n",
    "'''\n",
    "conclusion = '''create a pular dictionary specifc datastructure to handle the aggregate paragraphs. \n",
    "This will only be per lemma, \n",
    "as any aggregations from roots and relations of that sort can be managed in pandas and created by simple inheretance/reference\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, List, Any, Union, Tuple\n",
    "import pydantic\n",
    "from pydantic import ValidationError, validator, root_validator, Field, constr\n",
    "from pydantic_docx import Docx_Paragraph_and_Runs, read_docx #type:ignore\n",
    "from pydantic_docx_processor import create_sized_dataframe, expand_dataframe #type:ignore\n",
    "import re\n",
    "import json\n",
    "from itertools import compress, chain\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('feature_Frames_and_Indexes.pkl', 'rb') as file:\n",
    "    # Call load method to deserialze\n",
    "    output = pickle.load(file, encoding='utf-8')\n",
    "(\n",
    "parsed_object_list, #:List[Tuple[int,Docx_Paragraph_and_Runs]]\n",
    "parsed_object_lookup, #:Dict[int,Docx_Paragraph_and_Runs] = dict(parsed_object_list)\n",
    "doc_para_count, #: int = int(parsed_to_dict['total_encountered_paragraphs']) #type: ignore\n",
    "char_counts, #: Counter = parsed_to_dict['char_counts'] #type: ignore\n",
    "rootFrame,#:pd.DataFrame\n",
    "rootsubpieceFrame, #:pd.DataFrame\n",
    "lemmaFrame, #:pd.DataFrame\n",
    "nonentityParaFrame, #pd.DataFrame\n",
    "cleanerOutcomesDf #pd.DataFrame\n",
    "    ) = output\n",
    "paratext_lookup = {k:v.interogate__para_text() for k,v in parsed_object_lookup.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1982, 1983, 5971, 9318, 9786, 9787, 20565]\n",
      "(17241, 1)\n",
      "(17234, 1)\n"
     ]
    }
   ],
   "source": [
    "#first check the frame containing the success/failure boolean for the cleaner operation that was performed on the data in pydantic_docx ingestion\n",
    "# print(cleanerOutcomesDf['cleaner_success_outcomes'].unique())\n",
    "# print(cleanerOutcomesDf.groupby('cleaner_success_outcomes').count())\n",
    "cleanerOutcomesDf.dropna(subset=['paragraphIndex'],inplace=True)\n",
    "# print(cleanerOutcomesDf['cleaner_success_outcomes'].unique())\n",
    "# print(cleanerOutcomesDf.groupby('cleaner_success_outcomes').count())\n",
    "# print(cleanerOutcomesDf[cleanerOutcomesDf['cleaner_success_outcomes']==False])\n",
    "cleanerfailedInds = list(cleanerOutcomesDf[cleanerOutcomesDf['cleaner_success_outcomes']==False].index)\n",
    "print(cleanerfailedInds)\n",
    "\n",
    "\n",
    "all_para_text_frame = pd.Series(paratext_lookup).to_frame()\n",
    "all_para_text_frame = expand_dataframe(all_para_text_frame,doc_para_count)\n",
    "spread = 10\n",
    "window_of_inds = [list(range(i-spread,i+spread)) for i in cleanerfailedInds]\n",
    "\n",
    "# print(len(nonentityParaFrame.index.intersection(cleanerfailedInds))) #>>> 7, so all were captured in the nonentityParaFrame\n",
    "print(nonentityParaFrame.shape)\n",
    "nonentityParaFrame.drop(cleanerfailedInds, axis = 'index', inplace=True)\n",
    "print(nonentityParaFrame.shape)\n",
    "# all_para_text_frame.loc[window_of_inds[6]]\n",
    "\n",
    "#results: \n",
    "\n",
    "# [1982, 1983] #>\n",
    "\n",
    "   # all_para_text_frame.loc[window_of_inds[0]]\n",
    "      # 1981\tNaN\t\n",
    "      #># 1982\t\\t\\t\\t\\t\\t\\t\t\n",
    "      #># 1983\t\\t\\t\\t\\t\\t\\t\\t\\t\t\n",
    "      # 1984\tNaN\t\n",
    "      # 1985\tNaN\t\n",
    "      # 1986\tƁ\t\n",
    "# 5971 #>\n",
    "   # all_para_text_frame.loc[window_of_inds[2]]\n",
    "      #># 5971\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\n",
    "      # 5972\tFAKO Sonr\t\n",
    "      # 5973\tfako ? n. o\t \n",
    "# 9318 #>\n",
    "   # all_para_text_frame.loc[window_of_inds[3]]\n",
    "      # 9316\tGUYAAJI guyaaji, guyaale, guyaali pl.- nguyk...\t\n",
    "      # 9317\tNaN\t\n",
    "      #># 9318\t\\t\t\n",
    "      # 9319\tNaN\t\n",
    "      # 9320\tNaN\t\n",
    "      # 9321\tH\t\n",
    "      # 9322\tNaN\t\n",
    "# [9786, 9787] #>\n",
    "   # all_para_text_frame.loc[window_of_inds[4]]\n",
    "      # 9784\tnon-castrated male, stallion, bull\t\n",
    "      # 9785\tmâle non castré(D), étalon(Z), taureau(Z)\t\n",
    "      #># 9786\t\\t\\t\t\n",
    "      #># 9787\t\\t\\t\\t\t\n",
    "      # 9788\tHALƁ-\t\n",
    "      # 9789\thalɓude v.av DCZ CZ<FJ,M,NO> [haacude] cf...\t\n",
    "# 20565 #>\n",
    "   # all_para_text_frame.loc[window_of_inds[6]]\n",
    "      # 20564\tNaN\t20564\n",
    "      #># 20565\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\t20565\n",
    "      # 20566\tŊ\t20566\n",
    "      # 20567\tNaN\t20567\t\n",
    "\n",
    "# all values with a valid paragraph will have a value in 'paragraphIndex'. ie paragraphs that did not have a suppressed error during class assignment. By default these are lines with only '\\n'.\n",
    "#when parsing, the default was used, so any all whitespace paragraph will be nan in paragraphIndex.\n",
    "#when these values are dropped, the boolean column (indicating the successful post-processing of already created pydantic_docx class objects) yields True/False values.\n",
    "# 7 values were false, as shown above. Each was a line of only '\\t'. Lines with only '\\n' are not even read into the model.\n",
    "# adding control for this into the class object validation requirements may be a good idea. But better yet would be to pass a config with regex or simple roots to discard lines of a certain type. I'll add that to #TODO\n",
    "# we can safely drop these records.\n",
    "# ...and therefor, all are \"good\" for the next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following merge routine merges together the parents of one level of the heirarchy with their children. \n",
    "The parents then have their values forward-filled / duplicated to account for their headship over the child entities\n",
    "Each frame has an identity column with a boolean value indicating that index is the location of that entity.\n",
    "These are not needed for propogating headship and or child relationships, and these will not be forward-filled.\n",
    "As such, these will be removed from the entity frames before they are added to the entity heirarchy frame\n",
    "\n",
    "Precedence is as follows:\n",
    "root > subroot > lemmas > paragraphs\n",
    "\n",
    "However, the child relationship is non-exclusive to direct 'parents', such that a parent 'entity' may have a dhild from any of the levels below them.\n",
    "That said, the dictionary description and general structure would indicate paragraphs should only be direct children of Lemmas\n",
    ">paragraphs being defined as any line without an 'entity' such as root, subroot, or lemma.\n",
    ">any that are not would be a deviation. \n",
    "Therefor, any such instance needs to be captured and assessed, and should not be coerced into some other neighbors \"family\" by default, if at all.\n",
    "\n",
    "As a result, our routine for creating hierarchys must allow for any possible/permitted parent be available to match any children.\n",
    "\n",
    "So...\n",
    "\n",
    "Subroots:      possible parents are:      Roots\n",
    "Lemmas:        possible parents are:      Roots, Subroots\n",
    "Paragraphs:    possible parents are:      Roots, Subroots, Lemmas\n",
    "\n",
    "*Note: the term 'subroot' is sometimes described as 'root-subpiece', and these names may be understood interchangibly. The reason for the two names stems from two competing 'theories' or impressions of the nature of these entities. Initially I used the term subroot as a description of their subordinate position. The term subpiece has begun entering my vocabulary after discovering that many (if not all) of these are 'infixes', a core component of the Pular language. As a result any of these that are infixes are more than just a manual 'byte pair encoding' or common break point, but have specific meaning of their own.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraphIndex</th>\n",
       "      <th>is</th>\n",
       "      <th>text</th>\n",
       "      <th>mask</th>\n",
       "      <th>run_text_list</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>2415.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>ɓiraaɗam</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ɓiraaɗam , (ɗam) / ɓiraaɗe (ɗe)  , DFCZI  CZ&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15314</th>\n",
       "      <td>15314.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>kuuca</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[kuuca  , n.  , D]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15425</th>\n",
       "      <td>15425.0</td>\n",
       "      <td>root_subpiece</td>\n",
       "      <td>-IN-</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[-IN-]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>870.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>baaliki</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[baaliki  , n.  , D  [nayeejo]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4949</th>\n",
       "      <td>4949.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƊAAY-</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƊAAY-]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31161</th>\n",
       "      <td>31161.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>yeenga</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[yeenga , (nga) / jelle (ɗe)  , Z  [yeedirde, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10442</th>\n",
       "      <td>10442.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>hemre, hemere</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[hemre, hemere , (nde) / keme (ɗe)  , FCZ  CZ&lt;+&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14621</th>\n",
       "      <td>14621.0</td>\n",
       "      <td>root</td>\n",
       "      <td>KITIME</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[KITIME]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5941</th>\n",
       "      <td>5941.0</td>\n",
       "      <td>root</td>\n",
       "      <td>FAKAARE</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[FAKAARE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19720</th>\n",
       "      <td>19720.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>ndisawol</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ndisawol , (ngol)  , D]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       paragraphIndex             is           text                  mask  \\\n",
       "index                                                                       \n",
       "2415           2415.0          lemma       ɓiraaɗam  [True, False, False]   \n",
       "15314         15314.0          lemma          kuuca  [True, False, False]   \n",
       "15425         15425.0  root_subpiece           -IN-                [True]   \n",
       "870             870.0          lemma        baaliki  [True, False, False]   \n",
       "4949           4949.0           root          ƊAAY-                [True]   \n",
       "31161         31161.0          lemma         yeenga  [True, False, False]   \n",
       "10442         10442.0          lemma  hemre, hemere  [True, False, False]   \n",
       "14621         14621.0           root         KITIME                [True]   \n",
       "5941           5941.0           root        FAKAARE                [True]   \n",
       "19720         19720.0          lemma       ndisawol  [True, False, False]   \n",
       "\n",
       "                                           run_text_list  \n",
       "index                                                     \n",
       "2415   [ɓiraaɗam , (ɗam) / ɓiraaɗe (ɗe)  , DFCZI  CZ<...  \n",
       "15314                                 [kuuca  , n.  , D]  \n",
       "15425                                             [-IN-]  \n",
       "870                      [baaliki  , n.  , D  [nayeejo]]  \n",
       "4949                                             [ƊAAY-]  \n",
       "31161  [yeenga , (nga) / jelle (ɗe)  , Z  [yeedirde, ...  \n",
       "10442  [hemre, hemere , (nde) / keme (ɗe)  , FCZ  CZ<+>]  \n",
       "14621                                           [KITIME]  \n",
       "5941                                           [FAKAARE]  \n",
       "19720                           [ndisawol , (ngol)  , D]  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_entity_identity_frame = rootFrame[['is']].merge(rootsubpieceFrame[['is']],how='outer', on='index').merge(lemmaFrame[['is']],how='outer',on='index')\n",
    "all_entity_identity_frame.columns = ['is_root', 'is_root_subpiece','is_lemma']\n",
    "\n",
    "# rootFrame contains the permitted parents for subroots.\n",
    "# print(rootFrame)\n",
    "rootFrame['is']='root'\n",
    "root_parent = rootFrame.copy()\n",
    "#next the frame of permitted parents for lemmas is created by combining/overlaying roots and subroots\n",
    "rootsubpieceFrame['is'] = 'root_subpiece'\n",
    "any_roots = root_parent.combine_first(rootsubpieceFrame)\n",
    "\n",
    "#finally create the permitted parents of paragraphs (though we will want to examine any paragraphs subordinate directly to a root. These may indicate some datacleaning is needed, or may need to be removed entirely)\n",
    "lemmaFrame['is'] = 'lemma'\n",
    "anyEntityFrame = any_roots.combine_first(lemmaFrame)\n",
    "\n",
    "anyEntityFrame.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now these frames are set up, we can begin the routine. \n",
    "\n",
    "At each step, \n",
    "   >we merge the possible parents frame with the specific child frame.\n",
    "   >then we forward-fill the parent portion of the frame to indicate the headship for every record.\n",
    "   >- we want to 'unnest' this datastructure, and so we need to move from 'dictionary' style to 'record' style.\n",
    "   >- records require all pertinent infromation be present inside the record (records are usually defined as a single row in most industries)\n",
    "   >- so forward filling all possible parents will allow 'parentage' be infered by position / precedence on the page.\n",
    "   >  - a lemma is the child of the nearest 'parent' root UP the page from it, regardless if a root is directly below it.\n",
    "   >     - therefor forward-fill will allow these inferred relations be directly documented in each record, each row. \n",
    "   >     - SQL design says don't repeat yourself, but here we WANT to duplicate the parent value onto each child.\n",
    "   >     - This allows us to safely remove a 'child' from its context on the page without loosing who it's parents are.\n",
    "   >- then we merge in the 'frame' of next parent group, then child group, and repeat the forward filling \n",
    "   > \n",
    "   > *the process is iterative/recursive.*\n",
    "\n",
    "However, the parent/child relationships happen to align such that each next lower group of parents is composed of the parents + the child from the previous iteration...\n",
    "As a result we actually have a much simpler structure: we only need to merge each parent grouping directly, and forward fill all of those\n",
    "\n",
    "We will have some extra duplication from top parents being copied down on each level between them and their children, but we will solve this after we create it.\n",
    "\n",
    "The extra reason to group it this way is it does allow for a root to be declared on the same paragraph/line as a lemma, which is fairly common from manual review of the dictionary word document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraphIndex_main_root</th>\n",
       "      <th>is_main_root</th>\n",
       "      <th>text_main_root</th>\n",
       "      <th>mask_main_root</th>\n",
       "      <th>run_text_list_main_root</th>\n",
       "      <th>paragraphIndex_any_root</th>\n",
       "      <th>is_any_root</th>\n",
       "      <th>text_any_root</th>\n",
       "      <th>mask_any_root</th>\n",
       "      <th>run_text_list_any_root</th>\n",
       "      <th>paragraphIndex_any_entity</th>\n",
       "      <th>is_any_entity</th>\n",
       "      <th>text_any_entity</th>\n",
       "      <th>mask_any_entity</th>\n",
       "      <th>run_text_list_any_entity</th>\n",
       "      <th>paragraphIndex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>a</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[a  , prn,sbj,sf  , DFZH  Z&lt;-&gt;]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>a</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[a  , prn,sbj,sf  , DFZH  Z&lt;-&gt;]</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>a</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[a  , prn,sbj,sf  , DFZH  Z&lt;-&gt;]</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>8.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>-a</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[-a  , suf,pos  , F]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32502</th>\n",
       "      <td>32499.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUƳ-</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUƳ-]</td>\n",
       "      <td>32499.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUƳ-</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUƳ-]</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>ƴuuƴude</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuƴude  , v.av  , D]</td>\n",
       "      <td>32502.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32503</th>\n",
       "      <td>32503.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUƳ-  (2?)</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUƳ-  (2?)]</td>\n",
       "      <td>32503.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUƳ-  (2?)</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUƳ-  (2?)]</td>\n",
       "      <td>32503.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUƳ-  (2?)</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUƳ-  (2?)]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32504</th>\n",
       "      <td>32503.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUƳ-  (2?)</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUƳ-  (2?)]</td>\n",
       "      <td>32503.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUƳ-  (2?)</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUƳ-  (2?)]</td>\n",
       "      <td>32504.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>ƴuuƴude</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuƴude  , v.av  , D]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32505</th>\n",
       "      <td>32503.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUƳ-  (2?)</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUƳ-  (2?)]</td>\n",
       "      <td>32503.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUƳ-  (2?)</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUƳ-  (2?)]</td>\n",
       "      <td>32504.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>ƴuuƴude</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuƴude  , v.av  , D]</td>\n",
       "      <td>32505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32506</th>\n",
       "      <td>32503.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUƳ-  (2?)</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUƳ-  (2?)]</td>\n",
       "      <td>32503.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUƳ-  (2?)</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUƳ-  (2?)]</td>\n",
       "      <td>32504.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>ƴuuƴude</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuƴude  , v.av  , D]</td>\n",
       "      <td>32506.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32033 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       paragraphIndex_main_root is_main_root text_main_root mask_main_root  \\\n",
       "index                                                                        \n",
       "4                           4.0         root              A         [True]   \n",
       "5                           4.0         root              A         [True]   \n",
       "6                           4.0         root              A         [True]   \n",
       "7                           4.0         root              A         [True]   \n",
       "8                           4.0         root              A         [True]   \n",
       "...                         ...          ...            ...            ...   \n",
       "32502                   32499.0         root          ƳUUƳ-         [True]   \n",
       "32503                   32503.0         root    ƳUUƳ-  (2?)         [True]   \n",
       "32504                   32503.0         root    ƳUUƳ-  (2?)         [True]   \n",
       "32505                   32503.0         root    ƳUUƳ-  (2?)         [True]   \n",
       "32506                   32503.0         root    ƳUUƳ-  (2?)         [True]   \n",
       "\n",
       "      run_text_list_main_root  paragraphIndex_any_root is_any_root  \\\n",
       "index                                                                \n",
       "4                         [A]                      4.0        root   \n",
       "5                         [A]                      4.0        root   \n",
       "6                         [A]                      4.0        root   \n",
       "7                         [A]                      4.0        root   \n",
       "8                         [A]                      4.0        root   \n",
       "...                       ...                      ...         ...   \n",
       "32502                 [ƳUUƳ-]                  32499.0        root   \n",
       "32503           [ƳUUƳ-  (2?)]                  32503.0        root   \n",
       "32504           [ƳUUƳ-  (2?)]                  32503.0        root   \n",
       "32505           [ƳUUƳ-  (2?)]                  32503.0        root   \n",
       "32506           [ƳUUƳ-  (2?)]                  32503.0        root   \n",
       "\n",
       "      text_any_root mask_any_root run_text_list_any_root  \\\n",
       "index                                                      \n",
       "4                 A        [True]                    [A]   \n",
       "5                 A        [True]                    [A]   \n",
       "6                 A        [True]                    [A]   \n",
       "7                 A        [True]                    [A]   \n",
       "8                 A        [True]                    [A]   \n",
       "...             ...           ...                    ...   \n",
       "32502         ƳUUƳ-        [True]                [ƳUUƳ-]   \n",
       "32503   ƳUUƳ-  (2?)        [True]          [ƳUUƳ-  (2?)]   \n",
       "32504   ƳUUƳ-  (2?)        [True]          [ƳUUƳ-  (2?)]   \n",
       "32505   ƳUUƳ-  (2?)        [True]          [ƳUUƳ-  (2?)]   \n",
       "32506   ƳUUƳ-  (2?)        [True]          [ƳUUƳ-  (2?)]   \n",
       "\n",
       "       paragraphIndex_any_entity is_any_entity text_any_entity  \\\n",
       "index                                                            \n",
       "4                            4.0          root               A   \n",
       "5                            5.0         lemma               a   \n",
       "6                            5.0         lemma               a   \n",
       "7                            5.0         lemma               a   \n",
       "8                            8.0         lemma              -a   \n",
       "...                          ...           ...             ...   \n",
       "32502                    32500.0         lemma         ƴuuƴude   \n",
       "32503                    32503.0          root     ƳUUƳ-  (2?)   \n",
       "32504                    32504.0         lemma         ƴuuƴude   \n",
       "32505                    32504.0         lemma         ƴuuƴude   \n",
       "32506                    32504.0         lemma         ƴuuƴude   \n",
       "\n",
       "            mask_any_entity         run_text_list_any_entity  paragraphIndex  \n",
       "index                                                                         \n",
       "4                    [True]                              [A]             NaN  \n",
       "5      [True, False, False]  [a  , prn,sbj,sf  , DFZH  Z<->]             NaN  \n",
       "6      [True, False, False]  [a  , prn,sbj,sf  , DFZH  Z<->]             6.0  \n",
       "7      [True, False, False]  [a  , prn,sbj,sf  , DFZH  Z<->]             7.0  \n",
       "8      [True, False, False]             [-a  , suf,pos  , F]             NaN  \n",
       "...                     ...                              ...             ...  \n",
       "32502  [True, False, False]           [ƴuuƴude  , v.av  , D]         32502.0  \n",
       "32503                [True]                    [ƳUUƳ-  (2?)]             NaN  \n",
       "32504  [True, False, False]           [ƴuuƴude  , v.av  , D]             NaN  \n",
       "32505  [True, False, False]           [ƴuuƴude  , v.av  , D]         32505.0  \n",
       "32506  [True, False, False]           [ƴuuƴude  , v.av  , D]         32506.0  \n",
       "\n",
       "[32033 rows x 16 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#subroot-parent columns -> merged with <- lemma-parents columns\n",
    "entityInheritanceFrame = root_parent.merge(any_roots, on='index',how ='outer',suffixes=['_main_root',''],sort=True, validate='one_to_one')\n",
    "\n",
    "#'subroot-parent' and 'lemma-parent' columns -> merged with <- 'paragraph-parents' columns\n",
    "entityInheritanceFrame = entityInheritanceFrame.merge(anyEntityFrame, on='index',how ='outer',suffixes=['_any_root','_any_entity'],sort=True, validate='one_to_one')\n",
    "\n",
    "#before forward-fill, but we want to remove \"non-paragraph\" rows from our data (if present), since we don't care about empty paragraphs as children to our 'parents' (remembering that empty paragraphs are all np.nan)\n",
    "#this should have no np.nan values in the final paragraph-parents column, but lets check before we accidentally hide the evidence\n",
    "# print(entityInheritanceFrame.shape) >>> (15266, 12)\n",
    "entityInheritanceFrame = entityInheritanceFrame.dropna(subset=['paragraphIndex_any_entity'])\n",
    "# print(entityInheritanceFrame.shape) >>> (15266, 12)\n",
    "\n",
    "#forward-fill np.nan values in the whole dataframe\n",
    "entityInheritanceFrame = entityInheritanceFrame.fillna(method = 'ffill') #this can be skipped here, as it is redundant, but its a valuable midway point, and informative to review and check our assumptions\n",
    "\n",
    "#'subroot-parent' and 'lemma-parent' and 'paragraph-parents' columns -> merged with <- 'paragraphs' columns\n",
    "#note the 'paragraphs' paraFrame contains valid and invalid paragraphs, like the cleaner-output frame we dealt with above.\n",
    "#it specifically only contains the indexes of paragraphs that are valid AND did not contain on of the entities we've been dealing with (roots, subroots, lemmas)\n",
    "nan_free_paraFrame = nonentityParaFrame.dropna() #this will remove all non-paragraph records\n",
    "allParagraphsInheritanceFrame = entityInheritanceFrame.merge(nan_free_paraFrame, on='index',how ='outer',suffixes=['','_paragraphs'],sort=True, validate='one_to_one')                                       \n",
    "#since we dropped np.nan values above, the only nan values should be introduced by the paragraph merge. Where present in the paragraph columns, these will be the declaration columns of the lemmas and roots.\n",
    "#to solve that we will forwardfill all columns BUT the new paragraphIndex column, which will fill in the parents for the new paragraphs.\n",
    "allParagraphsInheritanceFrame.loc[:,entityInheritanceFrame.columns] = allParagraphsInheritanceFrame.loc[:,entityInheritanceFrame.columns].fillna(method = 'ffill')\n",
    "\n",
    "#here, we can choose to dropna in the dataframe, which will remove all records that do not have a child paragraph in them.\n",
    "#this will be necessary for creating records to match to the wordnet, since the paragraphs will be our glosses we need.\n",
    "#however, any record that has a lemma, but does not have paragraphs still has valuable information, so we don't want to discard these completely, we just can't use them directly to search the wordnet.\n",
    "\n",
    "# identify_condition = partial(lambda x: bool(re.match('is_',x)))\n",
    "# subroot_condition = partial(lambda x: bool(re.search('_root_subpiece',x)) or bool(re.search('_anyroot',x)))\n",
    "\n",
    "# entityInheritanceFrame\n",
    "allParagraphsInheritanceFrame\n",
    "#TODO break oneliners out, break roots out of those, check numbers with other checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['paragraphIndex_main_root', 'is_main_root', 'text_main_root',\n",
      "       'mask_main_root', 'run_text_list_main_root', 'paragraphIndex_any_root',\n",
      "       'is_any_root', 'text_any_root', 'mask_any_root',\n",
      "       'run_text_list_any_root', 'paragraphIndex_any_entity', 'is_any_entity',\n",
      "       'text_any_entity', 'mask_any_entity', 'run_text_list_any_entity',\n",
      "       'paragraphIndex'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(allParagraphsInheritanceFrame.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of entity declaration Frame:  15266\n",
      "summed length of all 3 entity frames:  16704\n",
      "difference between the two:  1438\n",
      "intersection of root-lemma frames:  1438\n",
      "intersection of subroot-lemma frames:  0\n",
      "intersection of root-subroot frames:  0\n",
      "number of content (non-entity) paragraphs:  16767\n"
     ]
    }
   ],
   "source": [
    "entityDeclarationParas = allParagraphsInheritanceFrame[allParagraphsInheritanceFrame['paragraphIndex'].isna()]\n",
    "entityDeclarationParasLEN = entityDeclarationParas.shape[0]\n",
    "print('length of entity declaration Frame: ',entityDeclarationParasLEN)\n",
    "summedEntityFramesLEN = rootFrame.shape[0]+rootsubpieceFrame.shape[0]+lemmaFrame.shape[0]\n",
    "print('summed length of all 3 entity frames: ',summedEntityFramesLEN)\n",
    "print('difference between the two: ',summedEntityFramesLEN-entityDeclarationParasLEN)\n",
    "print('intersection of root-lemma frames: ',len(rootFrame.index.intersection(lemmaFrame.index)))\n",
    "# >>>intersection of root-lemma frames:  1438\n",
    "print('intersection of subroot-lemma frames: ',len(rootsubpieceFrame.index.intersection(lemmaFrame.index)))\n",
    "# >>>intersection of subroot-lemma frames:  0\n",
    "print('intersection of root-subroot frames: ',len(rootFrame.index.intersection(rootsubpieceFrame.index)))\n",
    "# >>>intersection of root-subroot frames:  0\n",
    "paragraphRecordsFrame = allParagraphsInheritanceFrame[~allParagraphsInheritanceFrame['paragraphIndex'].isna()]\n",
    "print('number of content (non-entity) paragraphs: ',paragraphRecordsFrame.shape[0])\n",
    "#Conclusion: entityDeclarationParas is correct from our intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique parent types for paragraphs:  ['lemma']   ...  total found:  1 \n",
      "\n",
      "is_any_entity\n",
      "lemma    16767\n",
      "Name: paragraphIndex, dtype: int64\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print('unique parent types for paragraphs: ',paragraphRecordsFrame['is_any_entity'].unique(),'  ...  total found: ',len(paragraphRecordsFrame['is_any_entity'].unique()),'\\n')\n",
    "print(paragraphRecordsFrame.groupby('is_any_entity')['paragraphIndex'].count())\n",
    "# irregular_rootINDs = list(paragraphRecordsFrame[paragraphRecordsFrame['is_any_entity']=='root'].index)\n",
    "\n",
    "\n",
    "\n",
    "# paratext_lookup = {k:v.interogate__para_text() for k,v in parsed_object_lookup.items()}\n",
    "# all_para_text_frame = pd.Series(paratext_lookup).to_frame()\n",
    "# all_para_text_frame = expand_dataframe(all_para_text_frame,doc_para_count)\n",
    "# spread = 10\n",
    "# window_of_inds = [list(range(i-spread,i+spread)) for i in irregular_rootINDs]\n",
    "# # all_para_text_frame.loc[window_of_inds[0]]\n",
    "\n",
    "\n",
    "# print('\\n')\n",
    "# objects_list = [parsed_object_lookup[i] for i in irregular_rootINDs]\n",
    "# print(objects_list[0])\n",
    "# print(objects_list[0].cleaner())\n",
    "# print(objects_list[0])\n",
    "# print('\\n')\n",
    "\n",
    "# for o in objects_list:\n",
    "#    print(o,'\\n')\n",
    "\n",
    "# savetup = (paragraphRecordsFrame[paragraphRecordsFrame['is_any_entity']=='root'],objects_list)\n",
    "# with open('all_white_paras.pkl', 'wb') as file:\n",
    "#    pickle.dump(savetup, file)\n",
    "\n",
    "###Output of the above code### This was resolved by correcting the cleaner function within the pydlidocx script. It was not correctly raising the boolean success parameter. Fixed this and added a logger entry for this.\n",
    "# ['lemma' 'root']\n",
    "# is_any_entity\n",
    "# lemma    16770\n",
    "# root         4\n",
    "# Name: paragraphIndex, dtype: int64\n",
    "# [1982, 1983, 9318, 20565]\n",
    "\n",
    "\n",
    "# run_text=['\\t\\t\\t\\t\\t\\t'] run_font_name=['Helv 8pt'] para_first_line_indent=None run_italic=[None] para_left_indent=None paragraph_enumeration=1982 run_font_size_pt=[8.0] run_bold=[None] para_text='\\t\\t\\t\\t\\t\\t'\n",
    "# True\n",
    "# run_text=['\\t\\t\\t\\t\\t\\t'] run_font_name=['Helv 8pt'] para_first_line_indent=None run_italic=[None] para_left_indent=None paragraph_enumeration=1982 run_font_size_pt=[8.0] run_bold=[None] para_text='\\t\\t\\t\\t\\t\\t'\n",
    "\n",
    "\n",
    "# run_text=['\\t\\t\\t\\t\\t\\t'] run_font_name=['Helv 8pt'] para_first_line_indent=None run_italic=[None] para_left_indent=None paragraph_enumeration=1982 run_font_size_pt=[8.0] run_bold=[None] para_text='\\t\\t\\t\\t\\t\\t' \n",
    "\n",
    "# run_text=['\\t\\t\\t\\t\\t\\t\\t\\t'] run_font_name=['TmsRmn 10pt'] para_first_line_indent=None run_italic=[None] para_left_indent=None paragraph_enumeration=1983 run_font_size_pt=[None] run_bold=[None] para_text='\\t\\t\\t\\t\\t\\t\\t\\t' \n",
    "\n",
    "# run_text=['\\t'] run_font_name=['TmsRmn 10pt'] para_first_line_indent=None run_italic=[True] para_left_indent=None paragraph_enumeration=9318 run_font_size_pt=[None] run_bold=[None] para_text='\\t' \n",
    "\n",
    "# run_text=['\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'] run_font_name=['TmsRmn 8pt'] para_first_line_indent=None run_italic=[None] para_left_indent=None paragraph_enumeration=20565 run_font_size_pt=[8.0] run_bold=[None] para_text='\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraphIndex_main_root</th>\n",
       "      <th>is_main_root</th>\n",
       "      <th>text_main_root</th>\n",
       "      <th>mask_main_root</th>\n",
       "      <th>run_text_list_main_root</th>\n",
       "      <th>paragraphIndex_any_root</th>\n",
       "      <th>is_any_root</th>\n",
       "      <th>text_any_root</th>\n",
       "      <th>mask_any_root</th>\n",
       "      <th>run_text_list_any_root</th>\n",
       "      <th>paragraphIndex_any_entity</th>\n",
       "      <th>is_any_entity</th>\n",
       "      <th>text_any_entity</th>\n",
       "      <th>mask_any_entity</th>\n",
       "      <th>run_text_list_any_entity</th>\n",
       "      <th>paragraphIndex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>a</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[a  , prn,sbj,sf  , DFZH  Z&lt;-&gt;]</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>a</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[a  , prn,sbj,sf  , DFZH  Z&lt;-&gt;]</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>8.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>-a</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[-a  , suf,pos  , F]</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>8.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>-a</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[-a  , suf,pos  , F]</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>11.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>aan</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[aan  , prn,ind  , DFZH  [an]:Z&lt;-&gt;]</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32498</th>\n",
       "      <td>32495.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUW-</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUW-]</td>\n",
       "      <td>32495.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUW-</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUW-]</td>\n",
       "      <td>32496.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>ƴuuwaade</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuwaade  , v.mv  , D  [ƴuubaade, ƴooraade]]</td>\n",
       "      <td>32498.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32501</th>\n",
       "      <td>32499.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUƳ-</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUƳ-]</td>\n",
       "      <td>32499.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUƳ-</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUƳ-]</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>ƴuuƴude</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuƴude  , v.av  , D]</td>\n",
       "      <td>32501.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32502</th>\n",
       "      <td>32499.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUƳ-</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUƳ-]</td>\n",
       "      <td>32499.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUƳ-</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUƳ-]</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>ƴuuƴude</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuƴude  , v.av  , D]</td>\n",
       "      <td>32502.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32505</th>\n",
       "      <td>32503.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUƳ-  (2?)</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUƳ-  (2?)]</td>\n",
       "      <td>32503.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUƳ-  (2?)</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUƳ-  (2?)]</td>\n",
       "      <td>32504.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>ƴuuƴude</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuƴude  , v.av  , D]</td>\n",
       "      <td>32505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32506</th>\n",
       "      <td>32503.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUƳ-  (2?)</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUƳ-  (2?)]</td>\n",
       "      <td>32503.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUƳ-  (2?)</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUƳ-  (2?)]</td>\n",
       "      <td>32504.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>ƴuuƴude</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuƴude  , v.av  , D]</td>\n",
       "      <td>32506.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16767 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       paragraphIndex_main_root is_main_root text_main_root mask_main_root  \\\n",
       "index                                                                        \n",
       "6                           4.0         root              A         [True]   \n",
       "7                           4.0         root              A         [True]   \n",
       "9                           4.0         root              A         [True]   \n",
       "10                          4.0         root              A         [True]   \n",
       "12                          4.0         root              A         [True]   \n",
       "...                         ...          ...            ...            ...   \n",
       "32498                   32495.0         root          ƳUUW-         [True]   \n",
       "32501                   32499.0         root          ƳUUƳ-         [True]   \n",
       "32502                   32499.0         root          ƳUUƳ-         [True]   \n",
       "32505                   32503.0         root    ƳUUƳ-  (2?)         [True]   \n",
       "32506                   32503.0         root    ƳUUƳ-  (2?)         [True]   \n",
       "\n",
       "      run_text_list_main_root  paragraphIndex_any_root is_any_root  \\\n",
       "index                                                                \n",
       "6                         [A]                      4.0        root   \n",
       "7                         [A]                      4.0        root   \n",
       "9                         [A]                      4.0        root   \n",
       "10                        [A]                      4.0        root   \n",
       "12                        [A]                      4.0        root   \n",
       "...                       ...                      ...         ...   \n",
       "32498                 [ƳUUW-]                  32495.0        root   \n",
       "32501                 [ƳUUƳ-]                  32499.0        root   \n",
       "32502                 [ƳUUƳ-]                  32499.0        root   \n",
       "32505           [ƳUUƳ-  (2?)]                  32503.0        root   \n",
       "32506           [ƳUUƳ-  (2?)]                  32503.0        root   \n",
       "\n",
       "      text_any_root mask_any_root run_text_list_any_root  \\\n",
       "index                                                      \n",
       "6                 A        [True]                    [A]   \n",
       "7                 A        [True]                    [A]   \n",
       "9                 A        [True]                    [A]   \n",
       "10                A        [True]                    [A]   \n",
       "12                A        [True]                    [A]   \n",
       "...             ...           ...                    ...   \n",
       "32498         ƳUUW-        [True]                [ƳUUW-]   \n",
       "32501         ƳUUƳ-        [True]                [ƳUUƳ-]   \n",
       "32502         ƳUUƳ-        [True]                [ƳUUƳ-]   \n",
       "32505   ƳUUƳ-  (2?)        [True]          [ƳUUƳ-  (2?)]   \n",
       "32506   ƳUUƳ-  (2?)        [True]          [ƳUUƳ-  (2?)]   \n",
       "\n",
       "       paragraphIndex_any_entity is_any_entity text_any_entity  \\\n",
       "index                                                            \n",
       "6                            5.0         lemma               a   \n",
       "7                            5.0         lemma               a   \n",
       "9                            8.0         lemma              -a   \n",
       "10                           8.0         lemma              -a   \n",
       "12                          11.0         lemma             aan   \n",
       "...                          ...           ...             ...   \n",
       "32498                    32496.0         lemma        ƴuuwaade   \n",
       "32501                    32500.0         lemma         ƴuuƴude   \n",
       "32502                    32500.0         lemma         ƴuuƴude   \n",
       "32505                    32504.0         lemma         ƴuuƴude   \n",
       "32506                    32504.0         lemma         ƴuuƴude   \n",
       "\n",
       "            mask_any_entity                       run_text_list_any_entity  \\\n",
       "index                                                                        \n",
       "6      [True, False, False]                [a  , prn,sbj,sf  , DFZH  Z<->]   \n",
       "7      [True, False, False]                [a  , prn,sbj,sf  , DFZH  Z<->]   \n",
       "9      [True, False, False]                           [-a  , suf,pos  , F]   \n",
       "10     [True, False, False]                           [-a  , suf,pos  , F]   \n",
       "12     [True, False, False]            [aan  , prn,ind  , DFZH  [an]:Z<->]   \n",
       "...                     ...                                            ...   \n",
       "32498  [True, False, False]  [ƴuuwaade  , v.mv  , D  [ƴuubaade, ƴooraade]]   \n",
       "32501  [True, False, False]                         [ƴuuƴude  , v.av  , D]   \n",
       "32502  [True, False, False]                         [ƴuuƴude  , v.av  , D]   \n",
       "32505  [True, False, False]                         [ƴuuƴude  , v.av  , D]   \n",
       "32506  [True, False, False]                         [ƴuuƴude  , v.av  , D]   \n",
       "\n",
       "       paragraphIndex  \n",
       "index                  \n",
       "6                 6.0  \n",
       "7                 7.0  \n",
       "9                 9.0  \n",
       "10               10.0  \n",
       "12               12.0  \n",
       "...               ...  \n",
       "32498         32498.0  \n",
       "32501         32501.0  \n",
       "32502         32502.0  \n",
       "32505         32505.0  \n",
       "32506         32506.0  \n",
       "\n",
       "[16767 rows x 16 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphRecordsFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['paragraphIndex_main_root', 'is_main_root', 'text_main_root',\n",
      "       'mask_main_root', 'run_text_list_main_root', 'paragraphIndex_any_root',\n",
      "       'is_any_root', 'text_any_root', 'mask_any_root',\n",
      "       'run_text_list_any_root', 'paragraphIndex_any_entity', 'is_any_entity',\n",
      "       'text_any_entity', 'mask_any_entity', 'run_text_list_any_entity',\n",
      "       'paragraphIndex', 'run_text_list_paragraph'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\VSC-Workspace_PULAR\\.pular_venv\\lib\\site-packages\\ipykernel_launcher.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraphIndex_root</th>\n",
       "      <th>run_text_list_root</th>\n",
       "      <th>paragraphIndex_root_subpiece</th>\n",
       "      <th>run_text_list_root_subpiece</th>\n",
       "      <th>paragraphIndex_lemma</th>\n",
       "      <th>text_lemma</th>\n",
       "      <th>mask_lemma</th>\n",
       "      <th>run_text_list_lemma</th>\n",
       "      <th>paragraphIndex_paragraph</th>\n",
       "      <th>run_text_list_paragraph</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>a</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[a  , prn,sbj,sf  , DFZH  Z&lt;-&gt;]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[you (sg.)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>a</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[a  , prn,sbj,sf  , DFZH  Z&lt;-&gt;]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[tu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-a</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[-a  , suf,pos  , F]</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[your (sg.) (only with certain nouns such as t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-a</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[-a  , suf,pos  , F]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[ton, ta, tes (seulement pour certains substan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>aan</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[aan  , prn,ind  , DFZH  [an]:Z&lt;-&gt;]</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[you (sg.) (emphatic)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32498</th>\n",
       "      <td>32495.0</td>\n",
       "      <td>[ƳUUW-]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32496.0</td>\n",
       "      <td>ƴuuwaade</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuwaade  , v.mv  , D  [ƴuubaade, ƴooraade]]</td>\n",
       "      <td>32498.0</td>\n",
       "      <td>[s'incliner; se cabrer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32501</th>\n",
       "      <td>32499.0</td>\n",
       "      <td>[ƳUUƳ-]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>ƴuuƴude</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuƴude  , v.av  , D]</td>\n",
       "      <td>32501.0</td>\n",
       "      <td>[to increase in volume]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32502</th>\n",
       "      <td>32499.0</td>\n",
       "      <td>[ƳUUƳ-]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>ƴuuƴude</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuƴude  , v.av  , D]</td>\n",
       "      <td>32502.0</td>\n",
       "      <td>[augmenter de volume]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32505</th>\n",
       "      <td>32503.0</td>\n",
       "      <td>[ƳUUƳ-  (2?)]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32504.0</td>\n",
       "      <td>ƴuuƴude</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuƴude  , v.av  , D]</td>\n",
       "      <td>32505.0</td>\n",
       "      <td>[to give (push with?) the head to get out ?; t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32506</th>\n",
       "      <td>32503.0</td>\n",
       "      <td>[ƳUUƳ-  (2?)]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32504.0</td>\n",
       "      <td>ƴuuƴude</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuƴude  , v.av  , D]</td>\n",
       "      <td>32506.0</td>\n",
       "      <td>[donner (de?) la tête pour sortir; gonfler]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16767 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       paragraphIndex_root run_text_list_root  paragraphIndex_root_subpiece  \\\n",
       "index                                                                         \n",
       "6                      4.0                [A]                           NaN   \n",
       "7                      4.0                [A]                           NaN   \n",
       "9                      4.0                [A]                           NaN   \n",
       "10                     4.0                [A]                           NaN   \n",
       "12                     4.0                [A]                           NaN   \n",
       "...                    ...                ...                           ...   \n",
       "32498              32495.0            [ƳUUW-]                           NaN   \n",
       "32501              32499.0            [ƳUUƳ-]                           NaN   \n",
       "32502              32499.0            [ƳUUƳ-]                           NaN   \n",
       "32505              32503.0      [ƳUUƳ-  (2?)]                           NaN   \n",
       "32506              32503.0      [ƳUUƳ-  (2?)]                           NaN   \n",
       "\n",
       "      run_text_list_root_subpiece  paragraphIndex_lemma text_lemma  \\\n",
       "index                                                                \n",
       "6                             NaN                   5.0          a   \n",
       "7                             NaN                   5.0          a   \n",
       "9                             NaN                   8.0         -a   \n",
       "10                            NaN                   8.0         -a   \n",
       "12                            NaN                  11.0        aan   \n",
       "...                           ...                   ...        ...   \n",
       "32498                         NaN               32496.0   ƴuuwaade   \n",
       "32501                         NaN               32500.0    ƴuuƴude   \n",
       "32502                         NaN               32500.0    ƴuuƴude   \n",
       "32505                         NaN               32504.0    ƴuuƴude   \n",
       "32506                         NaN               32504.0    ƴuuƴude   \n",
       "\n",
       "                 mask_lemma                            run_text_list_lemma  \\\n",
       "index                                                                        \n",
       "6      [True, False, False]                [a  , prn,sbj,sf  , DFZH  Z<->]   \n",
       "7      [True, False, False]                [a  , prn,sbj,sf  , DFZH  Z<->]   \n",
       "9      [True, False, False]                           [-a  , suf,pos  , F]   \n",
       "10     [True, False, False]                           [-a  , suf,pos  , F]   \n",
       "12     [True, False, False]            [aan  , prn,ind  , DFZH  [an]:Z<->]   \n",
       "...                     ...                                            ...   \n",
       "32498  [True, False, False]  [ƴuuwaade  , v.mv  , D  [ƴuubaade, ƴooraade]]   \n",
       "32501  [True, False, False]                         [ƴuuƴude  , v.av  , D]   \n",
       "32502  [True, False, False]                         [ƴuuƴude  , v.av  , D]   \n",
       "32505  [True, False, False]                         [ƴuuƴude  , v.av  , D]   \n",
       "32506  [True, False, False]                         [ƴuuƴude  , v.av  , D]   \n",
       "\n",
       "       paragraphIndex_paragraph  \\\n",
       "index                             \n",
       "6                           6.0   \n",
       "7                           7.0   \n",
       "9                           9.0   \n",
       "10                         10.0   \n",
       "12                         12.0   \n",
       "...                         ...   \n",
       "32498                   32498.0   \n",
       "32501                   32501.0   \n",
       "32502                   32502.0   \n",
       "32505                   32505.0   \n",
       "32506                   32506.0   \n",
       "\n",
       "                                 run_text_list_paragraph  \n",
       "index                                                     \n",
       "6                                            [you (sg.)]  \n",
       "7                                                   [tu]  \n",
       "9      [your (sg.) (only with certain nouns such as t...  \n",
       "10     [ton, ta, tes (seulement pour certains substan...  \n",
       "12                                [you (sg.) (emphatic)]  \n",
       "...                                                  ...  \n",
       "32498                            [s'incliner; se cabrer]  \n",
       "32501                            [to increase in volume]  \n",
       "32502                              [augmenter de volume]  \n",
       "32505  [to give (push with?) the head to get out ?; t...  \n",
       "32506        [donner (de?) la tête pour sortir; gonfler]  \n",
       "\n",
       "[16767 rows x 10 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphRecordsFrame.columns\n",
    "cols = [\n",
    "   'paragraphIndex_main_root', \n",
    "   'is_main_root', \n",
    "   'text_main_root',\n",
    "   'mask_main_root', \n",
    "   'run_text_list_main_root', \n",
    "   'paragraphIndex_any_root',\n",
    "   'is_any_root', \n",
    "   'text_any_root', \n",
    "   'mask_any_root',\n",
    "   'run_text_list_any_root', \n",
    "   'paragraphIndex_any_entity', \n",
    "   'is_any_entity',\n",
    "   'text_any_entity', \n",
    "   'mask_any_entity', \n",
    "   'run_text_list_any_entity',\n",
    "   'paragraphIndex']\n",
    "\n",
    "expunge_root_from_subroot = [   \n",
    "   'paragraphIndex_any_root',\n",
    "   'is_any_root', \n",
    "   'text_any_root', \n",
    "   'mask_any_root',\n",
    "   'run_text_list_any_root', \n",
    "   # 'paragraphIndex_any_entity', \n",
    "   # 'is_any_entity',\n",
    "   # 'text_any_entity', \n",
    "   # 'mask_any_entity', \n",
    "   # 'run_text_list_any_entity',\n",
    "   ]\n",
    "drop_cols = [\n",
    "   # 'paragraphIndex_main_root', \n",
    "   'is_main_root', \n",
    "   'text_main_root',\n",
    "   'mask_main_root', \n",
    "   # 'run_text_list_main_root', \n",
    "   # 'paragraphIndex_any_root',\n",
    "   'is_any_root', \n",
    "   'text_any_root', \n",
    "   'mask_any_root',\n",
    "   # 'run_text_list_any_root', \n",
    "   # 'paragraphIndex_any_entity', \n",
    "   'is_any_entity',\n",
    "   # 'text_any_entity', \n",
    "   # 'mask_any_entity', \n",
    "   # 'run_text_list_any_entity',\n",
    "   # 'paragraphIndex'\n",
    "   ]\n",
    "\n",
    "colsnewnames = [\n",
    "   'paragraphIndex_root', \n",
    "   # 'is_main_root', \n",
    "   # 'text_main_root',\n",
    "   # 'mask_main_root', \n",
    "   'run_text_list_root', \n",
    "   'paragraphIndex_root_subpiece',\n",
    "   # 'is_any_root', \n",
    "   # 'text_any_root', \n",
    "   # 'mask_any_root',\n",
    "   'run_text_list_root_subpiece', \n",
    "   'paragraphIndex_lemma', \n",
    "   # 'is_any_entity',\n",
    "   'text_lemma', \n",
    "   'mask_lemma', \n",
    "   'run_text_list_lemma',\n",
    "   'paragraphIndex_paragraph',\n",
    "   'run_text_list_paragraph'\n",
    "   ]\n",
    "paragraphRecordsFrame['run_text_list_paragraph'] = paragraphRecordsFrame['paragraphIndex'].apply(lambda x: parsed_object_lookup[x].run_text)\n",
    "\n",
    "test_frame = paragraphRecordsFrame.copy(deep=True)\n",
    "test_frame.loc[test_frame['is_any_root']=='root',expunge_root_from_subroot] = np.nan\n",
    "print(test_frame.columns)\n",
    "test_frame.drop(drop_cols, axis = 1, inplace=True)\n",
    "test_frame.columns = colsnewnames\n",
    "test_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraphIndex_root</th>\n",
       "      <th>run_text_list_root</th>\n",
       "      <th>paragraphIndex_root_subpiece</th>\n",
       "      <th>run_text_list_root_subpiece</th>\n",
       "      <th>paragraphIndex_lemma</th>\n",
       "      <th>text_lemma</th>\n",
       "      <th>mask_lemma</th>\n",
       "      <th>run_text_list_lemma</th>\n",
       "      <th>paragraphIndex_paragraph</th>\n",
       "      <th>run_text_list_paragraph</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>a</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[a  , prn,sbj,sf  , DFZH  Z&lt;-&gt;]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[you (sg.)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>a</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[a  , prn,sbj,sf  , DFZH  Z&lt;-&gt;]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[tu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-a</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[-a  , suf,pos  , F]</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[your (sg.) (only with certain nouns such as t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-a</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[-a  , suf,pos  , F]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[ton, ta, tes (seulement pour certains substan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>aan</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[aan  , prn,ind  , DFZH  [an]:Z&lt;-&gt;]</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[you (sg.) (emphatic)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32498</th>\n",
       "      <td>32495.0</td>\n",
       "      <td>[ƳUUW-]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32496.0</td>\n",
       "      <td>ƴuuwaade</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuwaade  , v.mv  , D  [ƴuubaade, ƴooraade]]</td>\n",
       "      <td>32498.0</td>\n",
       "      <td>[s'incliner; se cabrer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32501</th>\n",
       "      <td>32499.0</td>\n",
       "      <td>[ƳUUƳ-]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>ƴuuƴude</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuƴude  , v.av  , D]</td>\n",
       "      <td>32501.0</td>\n",
       "      <td>[to increase in volume]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32502</th>\n",
       "      <td>32499.0</td>\n",
       "      <td>[ƳUUƳ-]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>ƴuuƴude</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuƴude  , v.av  , D]</td>\n",
       "      <td>32502.0</td>\n",
       "      <td>[augmenter de volume]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32505</th>\n",
       "      <td>32503.0</td>\n",
       "      <td>[ƳUUƳ-  (2?)]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32504.0</td>\n",
       "      <td>ƴuuƴude</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuƴude  , v.av  , D]</td>\n",
       "      <td>32505.0</td>\n",
       "      <td>[to give (push with?) the head to get out ?; t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32506</th>\n",
       "      <td>32503.0</td>\n",
       "      <td>[ƳUUƳ-  (2?)]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32504.0</td>\n",
       "      <td>ƴuuƴude</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuƴude  , v.av  , D]</td>\n",
       "      <td>32506.0</td>\n",
       "      <td>[donner (de?) la tête pour sortir; gonfler]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16767 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       paragraphIndex_root run_text_list_root  paragraphIndex_root_subpiece  \\\n",
       "index                                                                         \n",
       "6                      4.0                [A]                           NaN   \n",
       "7                      4.0                [A]                           NaN   \n",
       "9                      4.0                [A]                           NaN   \n",
       "10                     4.0                [A]                           NaN   \n",
       "12                     4.0                [A]                           NaN   \n",
       "...                    ...                ...                           ...   \n",
       "32498              32495.0            [ƳUUW-]                           NaN   \n",
       "32501              32499.0            [ƳUUƳ-]                           NaN   \n",
       "32502              32499.0            [ƳUUƳ-]                           NaN   \n",
       "32505              32503.0      [ƳUUƳ-  (2?)]                           NaN   \n",
       "32506              32503.0      [ƳUUƳ-  (2?)]                           NaN   \n",
       "\n",
       "      run_text_list_root_subpiece  paragraphIndex_lemma text_lemma  \\\n",
       "index                                                                \n",
       "6                             NaN                   5.0          a   \n",
       "7                             NaN                   5.0          a   \n",
       "9                             NaN                   8.0         -a   \n",
       "10                            NaN                   8.0         -a   \n",
       "12                            NaN                  11.0        aan   \n",
       "...                           ...                   ...        ...   \n",
       "32498                         NaN               32496.0   ƴuuwaade   \n",
       "32501                         NaN               32500.0    ƴuuƴude   \n",
       "32502                         NaN               32500.0    ƴuuƴude   \n",
       "32505                         NaN               32504.0    ƴuuƴude   \n",
       "32506                         NaN               32504.0    ƴuuƴude   \n",
       "\n",
       "                 mask_lemma                            run_text_list_lemma  \\\n",
       "index                                                                        \n",
       "6      [True, False, False]                [a  , prn,sbj,sf  , DFZH  Z<->]   \n",
       "7      [True, False, False]                [a  , prn,sbj,sf  , DFZH  Z<->]   \n",
       "9      [True, False, False]                           [-a  , suf,pos  , F]   \n",
       "10     [True, False, False]                           [-a  , suf,pos  , F]   \n",
       "12     [True, False, False]            [aan  , prn,ind  , DFZH  [an]:Z<->]   \n",
       "...                     ...                                            ...   \n",
       "32498  [True, False, False]  [ƴuuwaade  , v.mv  , D  [ƴuubaade, ƴooraade]]   \n",
       "32501  [True, False, False]                         [ƴuuƴude  , v.av  , D]   \n",
       "32502  [True, False, False]                         [ƴuuƴude  , v.av  , D]   \n",
       "32505  [True, False, False]                         [ƴuuƴude  , v.av  , D]   \n",
       "32506  [True, False, False]                         [ƴuuƴude  , v.av  , D]   \n",
       "\n",
       "       paragraphIndex_paragraph  \\\n",
       "index                             \n",
       "6                           6.0   \n",
       "7                           7.0   \n",
       "9                           9.0   \n",
       "10                         10.0   \n",
       "12                         12.0   \n",
       "...                         ...   \n",
       "32498                   32498.0   \n",
       "32501                   32501.0   \n",
       "32502                   32502.0   \n",
       "32505                   32505.0   \n",
       "32506                   32506.0   \n",
       "\n",
       "                                 run_text_list_paragraph  \n",
       "index                                                     \n",
       "6                                            [you (sg.)]  \n",
       "7                                                   [tu]  \n",
       "9      [your (sg.) (only with certain nouns such as t...  \n",
       "10     [ton, ta, tes (seulement pour certains substan...  \n",
       "12                                [you (sg.) (emphatic)]  \n",
       "...                                                  ...  \n",
       "32498                            [s'incliner; se cabrer]  \n",
       "32501                            [to increase in volume]  \n",
       "32502                              [augmenter de volume]  \n",
       "32505  [to give (push with?) the head to get out ?; t...  \n",
       "32506        [donner (de?) la tête pour sortir; gonfler]  \n",
       "\n",
       "[16767 rows x 10 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_frame['run_text_list_paragraph'] = test_frame['paragraphIndex_paragraph'].apply(lambda x: parsed_object_lookup[x].run_text)\n",
    "test_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32498</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32501</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32502</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32505</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32506</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16767 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2    3    4\n",
       "index                              \n",
       "6      True  False  False  NaN  NaN\n",
       "7      True  False  False  NaN  NaN\n",
       "9      True  False  False  NaN  NaN\n",
       "10     True  False  False  NaN  NaN\n",
       "12     True  False  False  NaN  NaN\n",
       "...     ...    ...    ...  ...  ...\n",
       "32498  True  False  False  NaN  NaN\n",
       "32501  True  False  False  NaN  NaN\n",
       "32502  True  False  False  NaN  NaN\n",
       "32505  True  False  False  NaN  NaN\n",
       "32506  True  False  False  NaN  NaN\n",
       "\n",
       "[16767 rows x 5 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_frame2 = test_frame['mask_lemma'].apply(pd.Series)\n",
    "test_frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_italic=[None] run_bold=[None] para_first_line_indent=None run_font_name=['TmsRmn 8pt'] para_text='ceertugol (Math.)(T): disjunction ; disjonction' paragraph_enumeration=24476 run_font_size_pt=[8.0] run_text=['ceertugol (Math.)(T): disjunction ; disjonction'] para_left_indent=116128800\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24476</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29842</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1      2    3    4\n",
       "index                              \n",
       "24476  False  True  False  NaN  NaN\n",
       "29842  False  True  False  NaN  NaN"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 200)\n",
    "print(parsed_object_lookup[24476])\n",
    "# print(paragraphRecordsFrame.loc[24474,:])\n",
    "\n",
    "# print(test_frame2[test_frame2[0]==False])\n",
    "test_frame.loc[24476]\n",
    "bold_where_not_expected = test_frame2[test_frame2[[1,2,3,4]].isin([True]).any(axis=1)] #94, only 2 dont\n",
    "\n",
    "bold_out_of_place = test_frame2[test_frame2[0]!=True] #only 2 arent in rows with lemmas 24476, 29842\n",
    "bold_where_not_expected\n",
    "# test_frame.loc[bold_where_not_expected.index]\n",
    "bold_out_of_place\n",
    "# test_frame.loc[24476]\n",
    "# test_frame.loc[29842]\n",
    "# paragraphRecordsFrame[paragraphRecordsFrame.isin(['SUK- (2?)']).any(axis=1)]\n",
    "# paragraphRecordsFrame.loc[25747] #additional lemmas are being claimed that aren't lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "allentitymasks = entityDeclarationParas['mask_any_entity'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_out_of_place = allentitymasks[allentitymasks[0]!=True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\VSC-Workspace_PULAR\\.pular_venv\\lib\\site-packages\\pandas\\core\\indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>paragraph_run_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4644</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[to hit hard on; , (neɗɗo),  to beat sb; to be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4645</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[taper fort sur(D); , (neɗɗo),  battre qqn, ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4675</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[to get angry at sb, scold sb; to complain; to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[se fâcher à qqn, gronder qqn; se plaindre; ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[to put o.s. across; , (neɗɗo),  to be an obst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[se mettre de travers(D); , (neɗɗo),  être obs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[to make small (intensive); , (neɗɗo),  to hum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6082</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[rendre petit (intensif); , (neɗɗo),  rabaisse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6681</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[representative of the So or Sidibe clan; warr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6682</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[représentant du clan Sow(Z) ou Sidibé; chef-g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12991</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[to hope(F); , (huunde),  to trust, rely on]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12992</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[espérer; , (huunde),  se fier à(Z)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13136</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[to follow; to accompany; to pursue sb; to con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13137</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[suivre; accompagner(D); poursuivre qqn(Z); co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13613</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[to pray, do prayers required in the Koran; to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[prier, faire les prières coraniques(Z); fêter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17001</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[to get lost, be lost, disappear (from sight);...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17002</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[se perdre, être perdu, disparaître (de vue(Z)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23000</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[to gather together, come together, be togethe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23001</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[faire assembler, amasser, se réunir, être ens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23874</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[to lay an ambush for sb; to be or get above; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23875</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[tendre une embuscade à qqn(CZ); être ou se me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24474</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[to separate definitively(F); , (e neɗɗo),  to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24475</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[se séparer définitivement; , (e neɗɗo),  romp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24613</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[to separate; to distinguish between(F); to sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24614</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[séparer; reconnaître, discerner (entre plusie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25040</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[to drive sth into sth else; , (e huunde),  to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25041</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[enfoncer qqch dans qqch; , (e huunde),  fixer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25240</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[to lock [fil(u)de]; , (neɗɗo),  to imprison sb]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25241</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[boucler, fermer à clé [fil(u)de]; , (neɗɗo), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25743</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[to succeed (sb) (Kane and Robinson, 1984); , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25744</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[succéder (à qqn); , (yolnde neɗɗo),  succéder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27916</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[to make dirty, foul (up); , (neɗɗo),  to slan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27917</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[salir, encrasser; , (neɗɗo),  calomnier qqn [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28201</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[to put in a lot; to introduce; to put in; to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28202</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[mettre en quantité(D); introduire(Z); mettre ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29840</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[to be, exist; , (e +inf.),  to begin, put o.s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29841</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[être, exister; , (e +inf.),  se mettre à fair...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30804</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[to tread on, step on, press on with the foot;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30805</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[marcher sur, fouler au pied, appuyer avec le ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2      3      4     5      6    7  \\\n",
       "index                                                        \n",
       "4644   False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "4645   False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "4675   False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "4676   False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "5980   False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "5981   False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "6081   False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "6082   False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "6681   False  False  False  False  False  True  False  NaN   \n",
       "6682   False  False  False  False  False  True  False  NaN   \n",
       "12991  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "12992  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "13136  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "13137  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "13613  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "13614  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "17001  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "17002  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "23000  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "23001  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "23874  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "23875  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "24474  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "24475  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "24613  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "24614  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "25040  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "25041  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "25240  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "25241  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "25743  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "25744  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "27916  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "27917  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "28201  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "28202  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "29840  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "29841  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "30804  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "30805  False   True  False    NaN    NaN   NaN    NaN  NaN   \n",
       "\n",
       "                                      paragraph_run_text  \n",
       "index                                                     \n",
       "4644   [to hit hard on; , (neɗɗo),  to beat sb; to be...  \n",
       "4645   [taper fort sur(D); , (neɗɗo),  battre qqn, ta...  \n",
       "4675   [to get angry at sb, scold sb; to complain; to...  \n",
       "4676   [se fâcher à qqn, gronder qqn; se plaindre; ba...  \n",
       "5980   [to put o.s. across; , (neɗɗo),  to be an obst...  \n",
       "5981   [se mettre de travers(D); , (neɗɗo),  être obs...  \n",
       "6081   [to make small (intensive); , (neɗɗo),  to hum...  \n",
       "6082   [rendre petit (intensif); , (neɗɗo),  rabaisse...  \n",
       "6681   [representative of the So or Sidibe clan; warr...  \n",
       "6682   [représentant du clan Sow(Z) ou Sidibé; chef-g...  \n",
       "12991       [to hope(F); , (huunde),  to trust, rely on]  \n",
       "12992               [espérer; , (huunde),  se fier à(Z)]  \n",
       "13136  [to follow; to accompany; to pursue sb; to con...  \n",
       "13137  [suivre; accompagner(D); poursuivre qqn(Z); co...  \n",
       "13613  [to pray, do prayers required in the Koran; to...  \n",
       "13614  [prier, faire les prières coraniques(Z); fêter...  \n",
       "17001  [to get lost, be lost, disappear (from sight);...  \n",
       "17002  [se perdre, être perdu, disparaître (de vue(Z)...  \n",
       "23000  [to gather together, come together, be togethe...  \n",
       "23001  [faire assembler, amasser, se réunir, être ens...  \n",
       "23874  [to lay an ambush for sb; to be or get above; ...  \n",
       "23875  [tendre une embuscade à qqn(CZ); être ou se me...  \n",
       "24474  [to separate definitively(F); , (e neɗɗo),  to...  \n",
       "24475  [se séparer définitivement; , (e neɗɗo),  romp...  \n",
       "24613  [to separate; to distinguish between(F); to sh...  \n",
       "24614  [séparer; reconnaître, discerner (entre plusie...  \n",
       "25040  [to drive sth into sth else; , (e huunde),  to...  \n",
       "25041  [enfoncer qqch dans qqch; , (e huunde),  fixer...  \n",
       "25240   [to lock [fil(u)de]; , (neɗɗo),  to imprison sb]  \n",
       "25241  [boucler, fermer à clé [fil(u)de]; , (neɗɗo), ...  \n",
       "25743  [to succeed (sb) (Kane and Robinson, 1984); , ...  \n",
       "25744  [succéder (à qqn); , (yolnde neɗɗo),  succéder...  \n",
       "27916  [to make dirty, foul (up); , (neɗɗo),  to slan...  \n",
       "27917  [salir, encrasser; , (neɗɗo),  calomnier qqn [...  \n",
       "28201  [to put in a lot; to introduce; to put in; to ...  \n",
       "28202  [mettre en quantité(D); introduire(Z); mettre ...  \n",
       "29840  [to be, exist; , (e +inf.),  to begin, put o.s...  \n",
       "29841  [être, exister; , (e +inf.),  se mettre à fair...  \n",
       "30804  [to tread on, step on, press on with the foot;...  \n",
       "30805  [marcher sur, fouler au pied, appuyer avec le ...  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_out_of_place.loc[:,'paragraph_run_text'] = entity_out_of_place.index.values\n",
    "entity_out_of_place.loc[:,'paragraph_run_text'] = entity_out_of_place.loc[:,'paragraph_run_text'].apply(lambda x: parsed_object_lookup[x].run_text)\n",
    "entity_out_of_place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4644</th>\n",
       "      <td>to hit hard on;</td>\n",
       "      <td>(neɗɗo)</td>\n",
       "      <td>to beat sb; to beat (heart)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4645</th>\n",
       "      <td>taper fort sur(D);</td>\n",
       "      <td>(neɗɗo)</td>\n",
       "      <td>battre qqn, taper qqn (Z); battre (coeur)(Z)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4675</th>\n",
       "      <td>to get angry at sb, scold sb; to complain; to ...</td>\n",
       "      <td>(e neɗɗo)</td>\n",
       "      <td>to complain to sb(F)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676</th>\n",
       "      <td>se fâcher à qqn, gronder qqn; se plaindre; bav...</td>\n",
       "      <td>(e neɗɗo)</td>\n",
       "      <td>se plaindre à qqn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>to put o.s. across;</td>\n",
       "      <td>(neɗɗo)</td>\n",
       "      <td>to be an obstacle to sb, get in the way, bar ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>se mettre de travers(D);</td>\n",
       "      <td>(neɗɗo)</td>\n",
       "      <td>être obstacle pour qqn, entraver, barrer la r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081</th>\n",
       "      <td>to make small (intensive);</td>\n",
       "      <td>(neɗɗo)</td>\n",
       "      <td>to humble, humiliate sb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6082</th>\n",
       "      <td>rendre petit (intensif);</td>\n",
       "      <td>(neɗɗo)</td>\n",
       "      <td>rabaisser, humilier qqn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6681</th>\n",
       "      <td>representative of the So or Sidibe clan; warri...</td>\n",
       "      <td>arɗo</td>\n",
       "      <td>for the Sidibe or So clan;</td>\n",
       "      <td>(pl.)</td>\n",
       "      <td>those who emigrate;</td>\n",
       "      <td>Ferooɓe</td>\n",
       "      <td>- clan Sidibe or So [Soosooɓe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6682</th>\n",
       "      <td>représentant du clan Sow(Z) ou Sidibé; chef-gu...</td>\n",
       "      <td>arɗo</td>\n",
       "      <td>pour le clan Sidibé ou Sô(M);</td>\n",
       "      <td>(pl.)</td>\n",
       "      <td>ceux qui émigrent(Seydou, 1977);</td>\n",
       "      <td>Ferooɓe</td>\n",
       "      <td>- clan Sidibé ou So (HIM(Sanankoua, 1990))  [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12991</th>\n",
       "      <td>to hope(F);</td>\n",
       "      <td>(huunde)</td>\n",
       "      <td>to trust, rely on</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12992</th>\n",
       "      <td>espérer;</td>\n",
       "      <td>(huunde)</td>\n",
       "      <td>se fier à(Z)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13136</th>\n",
       "      <td>to follow; to accompany; to pursue sb; to cont...</td>\n",
       "      <td>(huunde)</td>\n",
       "      <td>to do sth, accomplish sth; to join end to end</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13137</th>\n",
       "      <td>suivre; accompagner(D); poursuivre qqn(Z); con...</td>\n",
       "      <td>(huunde)</td>\n",
       "      <td>faire qqch, réaliser qqch (Z); joindre bout à...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13613</th>\n",
       "      <td>to pray, do prayers required in the Koran; to ...</td>\n",
       "      <td>(e neɗɗo)</td>\n",
       "      <td>to bless; to be a Muslim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614</th>\n",
       "      <td>prier, faire les prières coraniques(Z); fêter ...</td>\n",
       "      <td>(e neɗɗo)</td>\n",
       "      <td>bénir(Z); être musulman(Z)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17001</th>\n",
       "      <td>to get lost, be lost, disappear (from sight); ...</td>\n",
       "      <td>(neɗɗo, huunde)</td>\n",
       "      <td>not to know sb, sth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17002</th>\n",
       "      <td>se perdre, être perdu, disparaître (de vue(Z))...</td>\n",
       "      <td>(neɗɗo, huunde)</td>\n",
       "      <td>ignorer ou ne pas reconnaître qqn, qqch(Z)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23000</th>\n",
       "      <td>to gather together, come together, be together;</td>\n",
       "      <td>(e neɗɗo)</td>\n",
       "      <td>to wrestle with sb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23001</th>\n",
       "      <td>faire assembler, amasser, se réunir, être ense...</td>\n",
       "      <td>(e neɗɗo)</td>\n",
       "      <td>lutter avec qqn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23874</th>\n",
       "      <td>to lay an ambush for sb; to be or get above; t...</td>\n",
       "      <td>(huunde)</td>\n",
       "      <td>to prevent sth; to watch over</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23875</th>\n",
       "      <td>tendre une embuscade à qqn(CZ); être ou se met...</td>\n",
       "      <td>(huunde)</td>\n",
       "      <td>prévenir qqch(Z); surveiller(Z)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24474</th>\n",
       "      <td>to separate definitively(F);</td>\n",
       "      <td>(e neɗɗo)</td>\n",
       "      <td>to break with sb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24475</th>\n",
       "      <td>se séparer définitivement;</td>\n",
       "      <td>(e neɗɗo)</td>\n",
       "      <td>rompre avec qqn(Z)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24613</th>\n",
       "      <td>to separate; to distinguish between(F); to sha...</td>\n",
       "      <td>(neɗɗo e huunde)</td>\n",
       "      <td>to deprive sb of sth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24614</th>\n",
       "      <td>séparer; reconnaître, discerner (entre plusier...</td>\n",
       "      <td>(neɗɗo e huunde)</td>\n",
       "      <td>priver qqn de qqch(Z)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25040</th>\n",
       "      <td>to drive sth into sth else;</td>\n",
       "      <td>(e huunde)</td>\n",
       "      <td>to fix (to), place sth against sth else</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25041</th>\n",
       "      <td>enfoncer qqch dans qqch;</td>\n",
       "      <td>(e huunde)</td>\n",
       "      <td>fixer, accoler qqch contre qqch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25240</th>\n",
       "      <td>to lock [fil(u)de];</td>\n",
       "      <td>(neɗɗo)</td>\n",
       "      <td>to imprison sb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25241</th>\n",
       "      <td>boucler, fermer à clé [fil(u)de];</td>\n",
       "      <td>(neɗɗo)</td>\n",
       "      <td>enfermer qqn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25743</th>\n",
       "      <td>to succeed (sb) (Kane and Robinson, 1984);</td>\n",
       "      <td>(yolnde neɗɗo)</td>\n",
       "      <td>to succeed sb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25744</th>\n",
       "      <td>succéder (à qqn);</td>\n",
       "      <td>(yolnde neɗɗo)</td>\n",
       "      <td>succéder à qqn(Z)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27916</th>\n",
       "      <td>to make dirty, foul (up);</td>\n",
       "      <td>(neɗɗo)</td>\n",
       "      <td>to slander sb [ño'ude neɗɗo]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27917</th>\n",
       "      <td>salir, encrasser;</td>\n",
       "      <td>(neɗɗo)</td>\n",
       "      <td>calomnier qqn [ño'ude neɗɗo]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28201</th>\n",
       "      <td>to put in a lot; to introduce; to put in; to p...</td>\n",
       "      <td>(e +inf.)</td>\n",
       "      <td>to start to do sth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28202</th>\n",
       "      <td>mettre en quantité(D); introduire(Z); mettre d...</td>\n",
       "      <td>(e +inf.)</td>\n",
       "      <td>se mettre à faire qqch (z)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29840</th>\n",
       "      <td>to be, exist;</td>\n",
       "      <td>(e +inf.)</td>\n",
       "      <td>to begin, put o.s. to doing (F)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29841</th>\n",
       "      <td>être, exister;</td>\n",
       "      <td>(e +inf.)</td>\n",
       "      <td>se mettre à faire qqch(Z)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30804</th>\n",
       "      <td>to tread on, step on, press on with the foot;</td>\n",
       "      <td>(neɗɗo)</td>\n",
       "      <td>to treat sb without regard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30805</th>\n",
       "      <td>marcher sur, fouler au pied, appuyer avec le p...</td>\n",
       "      <td>(neɗɗo)</td>\n",
       "      <td>traiter qqn sans égards(Z)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0                 1  \\\n",
       "index                                                                        \n",
       "4644                                    to hit hard on;            (neɗɗo)   \n",
       "4645                                 taper fort sur(D);            (neɗɗo)   \n",
       "4675   to get angry at sb, scold sb; to complain; to ...         (e neɗɗo)   \n",
       "4676   se fâcher à qqn, gronder qqn; se plaindre; bav...         (e neɗɗo)   \n",
       "5980                                to put o.s. across;            (neɗɗo)   \n",
       "5981                           se mettre de travers(D);            (neɗɗo)   \n",
       "6081                         to make small (intensive);            (neɗɗo)   \n",
       "6082                           rendre petit (intensif);            (neɗɗo)   \n",
       "6681   representative of the So or Sidibe clan; warri...              arɗo   \n",
       "6682   représentant du clan Sow(Z) ou Sidibé; chef-gu...              arɗo   \n",
       "12991                                       to hope(F);           (huunde)   \n",
       "12992                                          espérer;           (huunde)   \n",
       "13136  to follow; to accompany; to pursue sb; to cont...          (huunde)   \n",
       "13137  suivre; accompagner(D); poursuivre qqn(Z); con...          (huunde)   \n",
       "13613  to pray, do prayers required in the Koran; to ...         (e neɗɗo)   \n",
       "13614  prier, faire les prières coraniques(Z); fêter ...         (e neɗɗo)   \n",
       "17001  to get lost, be lost, disappear (from sight); ...   (neɗɗo, huunde)   \n",
       "17002  se perdre, être perdu, disparaître (de vue(Z))...   (neɗɗo, huunde)   \n",
       "23000   to gather together, come together, be together;          (e neɗɗo)   \n",
       "23001  faire assembler, amasser, se réunir, être ense...         (e neɗɗo)   \n",
       "23874  to lay an ambush for sb; to be or get above; t...          (huunde)   \n",
       "23875  tendre une embuscade à qqn(CZ); être ou se met...          (huunde)   \n",
       "24474                      to separate definitively(F);          (e neɗɗo)   \n",
       "24475                        se séparer définitivement;          (e neɗɗo)   \n",
       "24613  to separate; to distinguish between(F); to sha...  (neɗɗo e huunde)   \n",
       "24614  séparer; reconnaître, discerner (entre plusier...  (neɗɗo e huunde)   \n",
       "25040                       to drive sth into sth else;         (e huunde)   \n",
       "25041                          enfoncer qqch dans qqch;         (e huunde)   \n",
       "25240                               to lock [fil(u)de];            (neɗɗo)   \n",
       "25241                 boucler, fermer à clé [fil(u)de];            (neɗɗo)   \n",
       "25743        to succeed (sb) (Kane and Robinson, 1984);     (yolnde neɗɗo)   \n",
       "25744                                 succéder (à qqn);     (yolnde neɗɗo)   \n",
       "27916                         to make dirty, foul (up);            (neɗɗo)   \n",
       "27917                                 salir, encrasser;            (neɗɗo)   \n",
       "28201  to put in a lot; to introduce; to put in; to p...         (e +inf.)   \n",
       "28202  mettre en quantité(D); introduire(Z); mettre d...         (e +inf.)   \n",
       "29840                                     to be, exist;          (e +inf.)   \n",
       "29841                                    être, exister;          (e +inf.)   \n",
       "30804     to tread on, step on, press on with the foot;            (neɗɗo)   \n",
       "30805  marcher sur, fouler au pied, appuyer avec le p...           (neɗɗo)   \n",
       "\n",
       "                                                       2      3  \\\n",
       "index                                                             \n",
       "4644                         to beat sb; to beat (heart)    NaN   \n",
       "4645        battre qqn, taper qqn (Z); battre (coeur)(Z)    NaN   \n",
       "4675                                to complain to sb(F)    NaN   \n",
       "4676                                   se plaindre à qqn    NaN   \n",
       "5980    to be an obstacle to sb, get in the way, bar ...    NaN   \n",
       "5981    être obstacle pour qqn, entraver, barrer la r...    NaN   \n",
       "6081                             to humble, humiliate sb    NaN   \n",
       "6082                             rabaisser, humilier qqn    NaN   \n",
       "6681                         for the Sidibe or So clan;   (pl.)   \n",
       "6682                      pour le clan Sidibé ou Sô(M);   (pl.)   \n",
       "12991                                  to trust, rely on    NaN   \n",
       "12992                                       se fier à(Z)    NaN   \n",
       "13136      to do sth, accomplish sth; to join end to end    NaN   \n",
       "13137   faire qqch, réaliser qqch (Z); joindre bout à...    NaN   \n",
       "13613                           to bless; to be a Muslim    NaN   \n",
       "13614                         bénir(Z); être musulman(Z)    NaN   \n",
       "17001                                not to know sb, sth    NaN   \n",
       "17002         ignorer ou ne pas reconnaître qqn, qqch(Z)    NaN   \n",
       "23000                                 to wrestle with sb    NaN   \n",
       "23001                                    lutter avec qqn    NaN   \n",
       "23874                      to prevent sth; to watch over    NaN   \n",
       "23875                    prévenir qqch(Z); surveiller(Z)    NaN   \n",
       "24474                                   to break with sb    NaN   \n",
       "24475                                 rompre avec qqn(Z)    NaN   \n",
       "24613                               to deprive sb of sth    NaN   \n",
       "24614                              priver qqn de qqch(Z)    NaN   \n",
       "25040            to fix (to), place sth against sth else    NaN   \n",
       "25041                    fixer, accoler qqch contre qqch    NaN   \n",
       "25240                                     to imprison sb    NaN   \n",
       "25241                                       enfermer qqn    NaN   \n",
       "25743                                      to succeed sb    NaN   \n",
       "25744                                  succéder à qqn(Z)    NaN   \n",
       "27916                       to slander sb [ño'ude neɗɗo]    NaN   \n",
       "27917                       calomnier qqn [ño'ude neɗɗo]    NaN   \n",
       "28201                                 to start to do sth    NaN   \n",
       "28202                         se mettre à faire qqch (z)    NaN   \n",
       "29840                    to begin, put o.s. to doing (F)    NaN   \n",
       "29841                          se mettre à faire qqch(Z)    NaN   \n",
       "30804                         to treat sb without regard    NaN   \n",
       "30805                         traiter qqn sans égards(Z)    NaN   \n",
       "\n",
       "                                        4        5  \\\n",
       "index                                                \n",
       "4644                                  NaN      NaN   \n",
       "4645                                  NaN      NaN   \n",
       "4675                                  NaN      NaN   \n",
       "4676                                  NaN      NaN   \n",
       "5980                                  NaN      NaN   \n",
       "5981                                  NaN      NaN   \n",
       "6081                                  NaN      NaN   \n",
       "6082                                  NaN      NaN   \n",
       "6681                 those who emigrate;   Ferooɓe   \n",
       "6682    ceux qui émigrent(Seydou, 1977);   Ferooɓe   \n",
       "12991                                 NaN      NaN   \n",
       "12992                                 NaN      NaN   \n",
       "13136                                 NaN      NaN   \n",
       "13137                                 NaN      NaN   \n",
       "13613                                 NaN      NaN   \n",
       "13614                                 NaN      NaN   \n",
       "17001                                 NaN      NaN   \n",
       "17002                                 NaN      NaN   \n",
       "23000                                 NaN      NaN   \n",
       "23001                                 NaN      NaN   \n",
       "23874                                 NaN      NaN   \n",
       "23875                                 NaN      NaN   \n",
       "24474                                 NaN      NaN   \n",
       "24475                                 NaN      NaN   \n",
       "24613                                 NaN      NaN   \n",
       "24614                                 NaN      NaN   \n",
       "25040                                 NaN      NaN   \n",
       "25041                                 NaN      NaN   \n",
       "25240                                 NaN      NaN   \n",
       "25241                                 NaN      NaN   \n",
       "25743                                 NaN      NaN   \n",
       "25744                                 NaN      NaN   \n",
       "27916                                 NaN      NaN   \n",
       "27917                                 NaN      NaN   \n",
       "28201                                 NaN      NaN   \n",
       "28202                                 NaN      NaN   \n",
       "29840                                 NaN      NaN   \n",
       "29841                                 NaN      NaN   \n",
       "30804                                 NaN      NaN   \n",
       "30805                                 NaN      NaN   \n",
       "\n",
       "                                                       6  \n",
       "index                                                     \n",
       "4644                                                 NaN  \n",
       "4645                                                 NaN  \n",
       "4675                                                 NaN  \n",
       "4676                                                 NaN  \n",
       "5980                                                 NaN  \n",
       "5981                                                 NaN  \n",
       "6081                                                 NaN  \n",
       "6082                                                 NaN  \n",
       "6681                      - clan Sidibe or So [Soosooɓe]  \n",
       "6682    - clan Sidibé ou So (HIM(Sanankoua, 1990))  [...  \n",
       "12991                                                NaN  \n",
       "12992                                                NaN  \n",
       "13136                                                NaN  \n",
       "13137                                                NaN  \n",
       "13613                                                NaN  \n",
       "13614                                                NaN  \n",
       "17001                                                NaN  \n",
       "17002                                                NaN  \n",
       "23000                                                NaN  \n",
       "23001                                                NaN  \n",
       "23874                                                NaN  \n",
       "23875                                                NaN  \n",
       "24474                                                NaN  \n",
       "24475                                                NaN  \n",
       "24613                                                NaN  \n",
       "24614                                                NaN  \n",
       "25040                                                NaN  \n",
       "25041                                                NaN  \n",
       "25240                                                NaN  \n",
       "25241                                                NaN  \n",
       "25743                                                NaN  \n",
       "25744                                                NaN  \n",
       "27916                                                NaN  \n",
       "27917                                                NaN  \n",
       "28201                                                NaN  \n",
       "28202                                                NaN  \n",
       "29840                                                NaN  \n",
       "29841                                                NaN  \n",
       "30804                                                NaN  \n",
       "30805                                                NaN  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_out_of_place_run_text_exploded = entity_out_of_place['paragraph_run_text'].apply(pd.Series)\n",
    "entity_out_of_place_run_text_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next steps, force entities to have a starting run with the value. \"match\" for the feature, not search\n",
    "#repeat cleaning, groupby lemma index, begin work on dictionary extraction with what I have. Record metrics of the values being filtered.\n",
    "# some ongoing attrition score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option(\"^display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [\n",
    "   \n",
    "   'txt_FulaLemmas',\n",
    "   'txt_FulaRoots',\n",
    "   \n",
    "   #extra\n",
    "   'txt_FulaAnnotations',\n",
    "   #gloss derivatives\n",
    "   'txt_FulaSenseEnglish',\n",
    "   'txt_FulaSenseFrench',\n",
    "   'txt_FulaSenseClassifications',\n",
    "   'txt_FulaSenseEnglishAnnotations',\n",
    "   'txt_FulaSenseFrenchAnnotations',\n",
    "\n",
    "   #lemma derivative\n",
    "   'txt_FulaDialects',\n",
    "   'txt_FulaPOSTags',\n",
    "   'txt_FulaSynonyms',\n",
    "\n",
    "\n",
    "   #agg\n",
    "   'txt_FulaInParenthesis',\n",
    "   'txt_POS',\n",
    "   'txt_RootOrigins'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re.compile('n\\\\.|(?<=\\\\()[^\\\\)]+|\\\\/')\n",
      "['n.', 'wsh', '/']\n",
      "['n.', 'wsh', '/']\n"
     ]
    }
   ],
   "source": [
    "# noun_patterns = [r'n\\.',r\"(?<=\\()[^\\)]+\",r\"\\/\"]\n",
    "# nounPatternRegex = re.compile('|'.join([p for p in noun_patterns]))\n",
    "# print(nounPatternRegex)\n",
    "# s = 'n. dfhjkgqh (wsh) askldjhf / asdfhjkkh'\n",
    "# print(re.findall(nounPatternRegex,s))\n",
    "# print(nounPatternRegex.findall(s))\n",
    "\n",
    "# if /, the next word is a plural. The plural also then usually has a (el) class after it. commas are multiple version\n",
    "# so each lemma noun may have a (class). The lemma may have one or multiple plurals, which will have a modified (class)\n",
    "# so have a nouns list? nouns may then be \n",
    "# [('n.',{bool}), #only needed if this gets added to all POS? Or maybe theres information in its use?\n",
    "# ([[{word}],{Optional[class]}]),  #singular\n",
    "   #([[{word}],{Optional[class]}])]   #plural\n",
    "\n",
    "# so nounStruct[0][1] is the flag for noun?\n",
    "   # one POS table, and noun will get added there. But the presence of a noun indicates to look here\n",
    "# classes may be found [sClass[1] for sClass in nounStruct[1]] will give all classes of singular, [sClass[1] for sClass in nounStruct[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now = datetime.now()\n",
    "# current_time = now.strftime(\"%Y-%m-%d_-_%H-%M-%S\")\n",
    "# print(f\"Experiment time: {current_time}\\nExperiment note: {experiment}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAssert(dct,val,typ:type, strict = True) -> Any:\n",
    "   out = dct.get(val,None)\n",
    "   if strict and typ is type(None):\n",
    "      raise NotImplementedError(f'this get/assert function cannot \"get\" None values safely, and a {val} type was passed for dict {dict}')\n",
    "   if strict and out is None:\n",
    "      raise KeyError(f\"the provided dict {dct} did not have the key: {val}\")\n",
    "   assert isinstance(out,typ), f\"the provided dict {dct} did not give {val} with the expected type: {typ}, but instead {out}\"\n",
    "   return out\n",
    "   \n",
    "def trustyGet(obj:Docx_Paragraph_and_Runs, feat: str, silent_return = True) -> str:\n",
    "      if not silent_return:\n",
    "         output : str = getattr(obj,feat,'')\n",
    "         if len(output) > 0:\n",
    "            return output\n",
    "         else:\n",
    "            raise AttributeError(f'trusty getter could not find: {feat}')\n",
    "      else:\n",
    "         output : str = getattr(obj,feat,'')\n",
    "         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dict_entry(pydantic.BaseModel): \n",
    "   '''\n",
    "   #True is used as default value, and must be changed to False if the feature is not found. This will catch not implemented, and incomplete updates\n",
    "   '''\n",
    "   irregularities: List[str] = []\n",
    "   lemma_index: int \n",
    "   paragraphs: List[Docx_Paragraph_and_Runs] = Field(...,min_items = 1)\n",
    "   lemma: str = Field(...,min_length = 1) #article\n",
    "   root: str\n",
    "   root_subpiece: Union[str,bool] = True #these will not be updated after initialization\n",
    "   root_metadata: Dict[str,Any]  #index,root_text, root_meta_data #article \n",
    "   root_origin: Union[str,bool] = True #these will not be updated after initialization\n",
    "   #Paragraph Derivatives: Glosses and Annotations\n",
    "   lemmaLine_runs: List[str] #these will not be updated after initialization\n",
    "   englishGlossLine_runs: Union[List[str],bool] = True #these will not be updated after initialization\n",
    "   frenchGlossLine_runs: Union[List[str],bool] = True #these will not be updated after initialization\n",
    "   FulaAnnotations_runs: Union[List[List[str]],bool]= True #these will not be updated after initialization\n",
    "\n",
    "   #Gloss Derivatives: English Senses\n",
    "   FulaSenseEnglish: Union[List[str],bool] = True #list of \"senses\" split by semicolons #article\n",
    "   FulaSenseEnglish_Count: Union[int,bool] = True #number of senses in english #aka FulaSenseClassifications #article\n",
    "   FulaSenseEnglish_Annotations: Union[List[str],bool] = True #contains the annotations (in parenthesis) for a given sense, if any #article \n",
    "   FulaSenseEnglish_Synonyms: Union[List[str],bool] = True #holds bracket text for a sense, suspected all synonyms. These may all occur at the end, and may be redundant with the synonyms provided at the head of the entry\n",
    "   FulaSenseEnglish_unusedContent: Union[List[str],bool] = True #holds any run text that is not contained in the above features\n",
    "   \n",
    "   #Gloss Derivatives: French Senses\n",
    "   FulaSenseFrench: Union[List[str],bool] = True #article\n",
    "   FulaSenseFrench_Count: Union[int,bool] = True #aka FulaSenseClassifications\n",
    "   FulaSenseFrench_Annotations: Union[List[str],bool] = True\n",
    "   FulaSenseFrench_Synonyms: Union[List[str],bool] = True\n",
    "   FulaSenseFrench_unusedContent: Union[List[str],bool] = True\n",
    "   \n",
    "   #lemma derivative\n",
    "   lemmaLine_unusedContent: List[Tuple[int,str]] #= Field(...) #int is index for run to allow tracing as entries are removed\n",
    "   FulaDialects: Union[List[str],bool] = True #article\n",
    "   FulaPOSTags: Union[List[str],bool] = True #article\n",
    "   FulaPOSClass: Union[List[str],bool] = True #Noun, Adj, Verb, Adv, Prn, ..., Complicated, Indeterminate\n",
    "   FulaNoun_NounsAndClass: Union[List[Tuple[str,str]],bool] = True #Pular has unique noun classes. Lemma will be copied here beside its class (\"noun\", \"nounclass\"), and any additional singular forms will be in additional tuples in this same list\n",
    "   FulaNoun_PluralsAndClass: Union[List[Tuple[str,str]],bool] = True #Dict provides plurals for nouns. Tuples will have (\"noun\", \"nounclass\")\n",
    "   FulaSynonyms: Union[List[str],bool] = True #article\n",
    "   FulaCrossRef: Union[List[str],bool] = True\n",
    "         # FulaVerbClass:\n",
    "   \n",
    "   class Config:\n",
    "      validate_all = True\n",
    "      validate_assignment = True\n",
    "      smart_union = True  \n",
    "      extra = 'forbid'\n",
    "\n",
    "   @root_validator(pre=True)\n",
    "   def _validate_and_build(cls, values: Dict[str,Any]) -> Dict[str, Any]:\n",
    "      # print(values)\n",
    "      newValues: Dict[str,Any] = {}\n",
    "      newValues['irregularities'] = []\n",
    "\n",
    "      ###PARAGRAPHS CHECK###\n",
    "      print(values)\n",
    "      newValues['paragraphs'] = getAssert(values,'paragraphs',list) #these come in as tuples(ind,para)\n",
    "      #TODO have more rigorous checks on para since so much depends on that even in this validation\n",
    "      assert isinstance(newValues['paragraphs'][0],tuple), 'currently paras are packaged in a tuple with their original doc index'\n",
    "      newValues['paragraphs'] = [p for i,p in newValues['paragraphs']]\n",
    "      if len(newValues['paragraphs']) == 0:\n",
    "         raise ValueError('given invalid paragraphs of zero length')\n",
    "      else: #logic for subsidary paragraphs\n",
    "         lemma_line = trustyGet(newValues['paragraphs'][0],feat = 'run_text', silent_return=False)\n",
    "         newValues['lemmaLine_runs'] = lemma_line\n",
    "         if len(newValues['paragraphs']) == 1:\n",
    "            newValues['englishGlossLine_runs'] = False\n",
    "            newValues['frenchGlossLine_runs'] = False\n",
    "         elif len(newValues['paragraphs']) == 2:\n",
    "            newValues['irregularities'].append('What:ambiguous, Where:paragraphs, Why: only one')\n",
    "            newValues['englishGlossLine_runs'] = False\n",
    "            newValues['frenchGlossLine_runs'] = False\n",
    "         elif len(newValues['paragraphs']) == 3:\n",
    "            newValues['englishGlossLine_runs'] = newValues['paragraphs'][1].get_run_text()\n",
    "            newValues['frenchGlossLine_runs'] = newValues['paragraphs'][2].get_run_text()\n",
    "         else: \n",
    "            newValues['englishGlossLine_runs'] = newValues['paragraphs'][1].get_run_text()\n",
    "            newValues['frenchGlossLine_runs'] = newValues['paragraphs'][2].get_run_text()\n",
    "            newValues['FulaAnnotations_runs'] = newValues['paragraphs'][3:].get_run_text()\n",
    "      \n",
    "      \n",
    "      try: ###LEMMA CHECK###\n",
    "         #reading in lemma results from first pass of pydantic parser\n",
    "         lemma_index, lemma_mask, lemmaLine_runs = getAssert(values,'lemma',tuple)\n",
    "         #checking for correct structure\n",
    "         lemma_matched_runs = list(compress(lemmaLine_runs,lemma_mask))\n",
    "         if len(lemma_matched_runs) > 1:\n",
    "            newValues['irregularities'].append('What:Unexpected, Where: Lemmas, Why: the merge routines should aggregate adjacent runs with same features. Multiple Lemma runs should not be possible if Bold is contiguous')\n",
    "         lemma_text = ''.join(chain(lemma_matched_runs)).strip()\n",
    "            #TODO have better control for expected structure that these runs should be adjacent (and only should be one)\n",
    "         #saving values. These will have to pass type check of declared attribute types for validation to succeed\n",
    "         newValues['lemma'] = lemma_text\n",
    "         newValues['lemma_index'] = lemma_index\n",
    "         newValues['lemmaLine_runs'] = lemmaLine_runs\n",
    "         used_run_mask = lemma_mask\n",
    "      except Exception as e:\n",
    "         #exception lemma check\n",
    "         raise RuntimeError('failed lemma check') from e\n",
    "\n",
    "      try: ###ROOT CHECK###\n",
    "         #reading in root results from first pass of pydantic parser\n",
    "         #checking for correct structure\n",
    "         root_index, root_mask, rootLine_runs = getAssert(values,'root',tuple)\n",
    "         root_matched_runs = list(compress(rootLine_runs,root_mask))\n",
    "         if len(root_matched_runs) > 1:\n",
    "            newValues['irregularities'].append('What:Unexpected, Where: Root, Why: the merge routines should aggregate adjacent runs with same features. Multiple Root runs should not be possible if Fontsize is contiguous and unique')\n",
    "         root_text = ''.join(chain(root_matched_runs)).strip()\n",
    "         if root_index == newValues['lemma_index']:\n",
    "            newValues['irregularities'].append('What:inconsistent, Where: Lemmas and Root, Why:normally root and lemma are on different lines. This has them sharing, which may indicate a lack of other content')\n",
    "            used_run_mask = [any(run) for run in list(zip(used_run_mask,root_mask))]\n",
    "            rootLine_runs = False\n",
    "         newValues['root'] = root_text\n",
    "         newValues['root_metadata'] = {'root_index': root_index, 'root_runs':rootLine_runs}\n",
    "      except Exception as e:\n",
    "         #exception ROOT check\n",
    "         raise RuntimeError('failed ROOT check') from e\n",
    "\n",
    "      try: ###ROOT-Subpiece CHECK###\n",
    "         #iterating in case a subroot is present\n",
    "         root_index, root_mask, rootLine_runs = getAssert(values,'root',tuple)\n",
    "         root_matched_runs = list(compress(rootLine_runs,root_mask))\n",
    "         if len(root_matched_runs) > 1:\n",
    "            newValues['irregularities'].append('What:Unexpected, Where: Root-Subpiece, Why: the merge routines should aggregate adjacent runs with same features. Multiple Root runs should not be possible if Fontsize is contiguous and unique')\n",
    "         root_subpiece_text = ''.join(chain(root_matched_runs)).strip()\n",
    "         if root_index == newValues['lemma_index']:\n",
    "            newValues['irregularities'].append('What:inconsistent, Where: Lemmas and Root-Subpiece, Why:normally root and lemma are on different lines. This has them sharing, which may indicate a lack of other content')\n",
    "            used_run_mask = [any(run) for run in list(zip(used_run_mask,root_mask))]\n",
    "            rootLine_runs = False\n",
    "         newValues['root_subpiece'] = root_subpiece_text\n",
    "         newValues['root_metadata'] = {'root_subpiece_index': root_index, 'root_subpiece_runs':rootLine_runs}\n",
    "      except AssertionError as e:\n",
    "         newValues['root_subpiece'] = False\n",
    "      except Exception as e:\n",
    "         #exception ROOT-Subpiece check\n",
    "         raise RuntimeError('failed ROOT-Subpiece check') from e\n",
    "\n",
    "      #determining lemmaLine_unusedContent\n",
    "      unused_run_mask = [not r for r in used_run_mask]\n",
    "      print(list(compress(enumerate(newValues['lemmaLine_runs']),unused_run_mask)))\n",
    "      newValues['lemmaLine_unusedContent'] = list(compress(enumerate(newValues['lemmaLine_runs']),unused_run_mask))\n",
    "      \n",
    "      return newValues\n",
    "\n",
    "   def parse_senses(self):\n",
    "      #TODO\n",
    "      return\n",
    "\n",
    "   def parse_glossRemainder(self):\n",
    "      #TODO\n",
    "      return\n",
    "\n",
    "   def parse_lemmaLine(self):\n",
    "      #TODO\n",
    "      return\n",
    "\n",
    "   def parse_lemmaLineRemainder(self):\n",
    "      #TODO\n",
    "      return\n",
    "\n",
    "   def get_rootOrigin(self):\n",
    "      #TODO\n",
    "      return\n",
    " \n",
    "   def give_entryText(self, joiner = '\\t') -> str: #article\n",
    "      return joiner.join([para.trustyGet('para_text') for para in self.paragraphs])\n",
    "\n",
    "   \n",
    "      \n",
    "            \n",
    "# dict_entry.parse_obj({'paragraphs':[b for a,b in parsed_object_list[5:8]]})\n",
    "\n",
    "# incoming = {\n",
    "#    'paragraphs': List[Docx_Paragraph_and_Runs],\n",
    "#    'root': List[int,str,List[bool]],\n",
    "#    'lemma': List[int,str,List[bool]],\n",
    "#    # 'pos': \n",
    "# }\n",
    "\n",
    "# [\n",
    "#    ['paras'], #obj\n",
    "#    ['parsed_paras'], #pydocx\n",
    "#    ['roots'], #name, fill forwards\n",
    "#    ['lemmas']  #text, fill forwards\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('parsed_objectClass_outcomes_dict.pkl', 'rb') as file:\n",
    "#     # Call load method to deserialze\n",
    "#     parsed_objectClass_outcomes_dict = pickle.load(file, encoding='utf-8')\n",
    "\n",
    "# parsed_object_list = parsed_objectClass_outcomes_dict['parsed_object_list'] \n",
    "# para_text_lookup = parsed_objectClass_outcomes_dict['para_text_lookup'] \n",
    "# root_ind_list = parsed_objectClass_outcomes_dict['root_ind_list'] \n",
    "# subroot_ind_list = parsed_objectClass_outcomes_dict['subroot_ind_list'] \n",
    "# lemma_ind_list = parsed_objectClass_outcomes_dict['lemma_ind_list'] \n",
    "# root_and_lemma_one_line = parsed_objectClass_outcomes_dict['root_and_lemma_one_line'] \n",
    "# root_lookup = parsed_objectClass_outcomes_dict['root_lookup'] \n",
    "# lemma_lookup = parsed_objectClass_outcomes_dict['lemma_lookup'] \n",
    "# # char_counts = parsed_objectClass_outcomes_dict['char_counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docx_filename = \"pasted_docx page 1.docx\"\n",
    "docx_filename = \"Fula_Dictionary-repaired.docx\"\n",
    "parsed_to_dict = read_docx(docx_filename)\n",
    "\n",
    "outcomes_dict = monolith_root_and_lemma_processor(parsed_to_dict['parsed_object_list'],parsed_to_dict['char_counts'])\n",
    "\n",
    "parsed_object_list = outcomes_dict['parsed_object_list'] \n",
    "para_text_lookup = outcomes_dict['para_text_lookup'] \n",
    "root_ind_list = outcomes_dict['root_ind_list'] \n",
    "subroot_ind_list = outcomes_dict['subroot_ind_list'] \n",
    "lemma_ind_list = outcomes_dict['lemma_ind_list'] \n",
    "root_and_lemma_one_line = outcomes_dict['root_and_lemma_one_line'] \n",
    "root_lookup = outcomes_dict['root_lookup'] \n",
    "lemma_lookup = outcomes_dict['lemma_lookup'] \n",
    "char_counts = outcomes_dict['char_counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Creating lists of indexes for use in remaining processing\n",
    "\n",
    "# # # print(len(parsed_object_list)) #32040\n",
    "# #note this parsed paras are packaged with the original para number in the docx\n",
    "# #therefore 32507 is the index to use, but len of that IS 32040, since ~500 were empty paragraphs that were not parsed\n",
    "# parsed_para_indexes = [i for i,p in parsed_object_list]\n",
    "\n",
    "# lim = 32507\n",
    "# # rootInds = [x for x in root_ind_list if x < lim]\n",
    "# rootInds=root_ind_list\n",
    "# # subRootInds = [x for x in subroot_ind_list if x < lim]\n",
    "# subRootInds=subroot_ind_list\n",
    "# # lemmaInds = [x for x in lemma_ind_list if x < lim]\n",
    "# lemmaInds=lemma_ind_list\n",
    "\n",
    "# allroots = rootInds.copy()\n",
    "# allroots.extend(subRootInds)\n",
    "# allroots = sorted(allroots)\n",
    "# allEntities = allroots.copy()\n",
    "# allEntities.extend(lemmaInds)\n",
    "# allEntities = sorted(set(allEntities))\n",
    "# print('allEntities: ',len(allEntities))\n",
    "\n",
    "\n",
    "# # all_paras = [i for i,obj in parsed_object_list if i < lim]\n",
    "# normal_para = parsed_para_indexes.copy()\n",
    "# [normal_para.remove(i) for i in allEntities]\n",
    "# print('normal_para: ',len(normal_para))\n",
    "\n",
    "# # normal_para = [x for x in parsed_para_indexes if all([x not in rootInds, x not in lemmaInds, x not in subRootInds])]\n",
    "# # print(normal_para)\n",
    "# # print(allroots)\n",
    "# root_aligned_lemmas = list(closest(pairwise(allroots), lemmaInds))\n",
    "# lemma_aligned_paras = list(closest(pairwise(lemmaInds),normal_para))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('entity_index_schema.pkl', 'rb') as file:\n",
    "#     # Call load method to deserialze\n",
    "#     entity_index_schema = pickle.load(file, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for r,v1 in entity_index_schema.items():\n",
    "#    root = (r,root_lookup[r][1],root_lookup[r][2])\n",
    "#    if isinstance(v1,dict):\n",
    "#       for k,v in v1.items():\n",
    "#          if k in subroot_ind_list:\n",
    "#             subroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paragraphs': [(8, Docx_Paragraph_and_Runs(run_italic=[None, True, None], para_left_indent=182880, run_font_name=['TmsRmn 10pt', 'TmsRmn 10pt', 'Helv 8pt'], paragraph_enumeration=8, run_font_size_pt=[None, None, 8.0], para_first_line_indent=-91440, run_text=['-a  ', 'suf,pos  ', 'F'], run_bold=[True, None, None], para_text='-a  suf,pos  F')), (9, Docx_Paragraph_and_Runs(run_italic=[None], para_left_indent=274320, run_font_name=['TmsRmn 10pt'], paragraph_enumeration=9, run_font_size_pt=[None], para_first_line_indent=-91440, run_text=['your (sg.) (only with certain nouns such as those which refer to close family members)'], run_bold=[None], para_text='your (sg.) (only with certain nouns such as those which refer to close family members)')), (10, Docx_Paragraph_and_Runs(run_italic=[None], para_left_indent=274320, run_font_name=['TmsRmn 10pt'], paragraph_enumeration=10, run_font_size_pt=[None], para_first_line_indent=-91440, run_text=['ton, ta, tes (seulement pour certains substantifs, tels ceux qui se rapportent aux membres de la proche famille)'], run_bold=[None], para_text='ton, ta, tes (seulement pour certains substantifs, tels ceux qui se rapportent aux membres de la proche famille)'))], 'root': (4, [True], ['A']), 'lemma': (8, [True, False, False], ['-a  ', 'suf,pos  ', 'F'])}\n",
      "[(1, 'suf,pos  '), (2, 'F')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_entry(irregularities=[], lemma_index=8, paragraphs=[Docx_Paragraph_and_Runs(run_italic=[None, True, None], para_left_indent=116128800, run_font_name=['TmsRmn 10pt', 'TmsRmn 10pt', 'Helv 8pt'], paragraph_enumeration=8, run_font_size_pt=[None, None, 8.0], para_first_line_indent=-91440, run_text=['-a  ', 'suf,pos  ', 'F'], run_bold=[True, None, None], para_text='-a  suf,pos  F'), Docx_Paragraph_and_Runs(run_italic=[None], para_left_indent=174193200, run_font_name=['TmsRmn 10pt'], paragraph_enumeration=9, run_font_size_pt=[None], para_first_line_indent=-91440, run_text=['your (sg.) (only with certain nouns such as those which refer to close family members)'], run_bold=[None], para_text='your (sg.) (only with certain nouns such as those which refer to close family members)'), Docx_Paragraph_and_Runs(run_italic=[None], para_left_indent=174193200, run_font_name=['TmsRmn 10pt'], paragraph_enumeration=10, run_font_size_pt=[None], para_first_line_indent=-91440, run_text=['ton, ta, tes (seulement pour certains substantifs, tels ceux qui se rapportent aux membres de la proche famille)'], run_bold=[None], para_text='ton, ta, tes (seulement pour certains substantifs, tels ceux qui se rapportent aux membres de la proche famille)')], lemma='-a', root='A', root_subpiece='A', root_metadata={'root_subpiece_index': 4, 'root_subpiece_runs': ['A']}, root_origin=True, lemmaLine_runs=['-a  ', 'suf,pos  ', 'F'], englishGlossLine_runs=['your (sg.) (only with certain nouns such as those which refer to close family members)'], frenchGlossLine_runs=['ton, ta, tes (seulement pour certains substantifs, tels ceux qui se rapportent aux membres de la proche famille)'], FulaAnnotations_runs=True, FulaSenseEnglish=True, FulaSenseEnglish_Count=True, FulaSenseEnglish_Annotations=True, FulaSenseEnglish_Synonyms=True, FulaSenseEnglish_unusedContent=True, FulaSenseFrench=True, FulaSenseFrench_Count=True, FulaSenseFrench_Annotations=True, FulaSenseFrench_Synonyms=True, FulaSenseFrench_unusedContent=True, lemmaLine_unusedContent=[(1, 'suf,pos  '), (2, 'F')], FulaDialects=True, FulaPOSTags=True, FulaPOSClass=True, FulaNoun_NounsAndClass=True, FulaNoun_PluralsAndClass=True, FulaSynonyms=True, FulaCrossRef=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result = []\n",
    "# for i in parsed_object_list[5:15]:\n",
    "#    result.append(dict_entry({i))\n",
    "# print(root_lookup[4])\n",
    "# print(para_text_lookup[3])\n",
    "# root_container = [(ind, mask, rootLine_runs) for ind, mask, rootLine_runs in getAssert(values,'root',list)]\n",
    "shorter_obj_list = parsed_object_list[:300]\n",
    "# for r, l\n",
    "inds = [8,9,10]\n",
    "\n",
    "dct = {\n",
    "   'paragraphs':[o for o in shorter_obj_list if o[0] in inds],\n",
    "   'root': (4,root_lookup[4][1],root_lookup[4][2]),\n",
    "   'lemma': (inds[0],lemma_lookup[inds[0]][1],lemma_lookup[inds[0]][2])\n",
    "}\n",
    "dict_entry.parse_obj(dct)\n",
    "\n",
    "# {'paragraphs': [(9, \n",
    "#    Docx_Paragraph_and_Runs(run_italic=[None], para_left_indent=274320, run_font_name=['TmsRmn 10pt'], paragraph_enumeration=9, run_font_size_pt=[None], para_first_line_indent=-91440, run_text=['your (sg.) (only with certain nouns such as those which refer to close family members)'], run_bold=[None], para_text='your (sg.) (only with certain nouns such as those which refer to close family members)')), (10, Docx_Paragraph_and_Runs(run_italic=[None], para_left_indent=274320, run_font_name=['TmsRmn 10pt'], paragraph_enumeration=10, run_font_size_pt=[None], para_first_line_indent=-91440, run_text=['ton, ta, tes (seulement pour certains substantifs, tels ceux qui se rapportent aux membres de la proche famille)'], run_bold=[None], para_text='ton, ta, tes (seulement pour certains substantifs, tels ceux qui se rapportent aux membres de la proche famille)')), \n",
    "#    (11, Docx_Paragraph_and_Runs(run_italic=[None, True, None], para_left_indent=182880, run_font_name=['TmsRmn 10pt', 'TmsRmn 10pt', 'Helv 8pt'], paragraph_enumeration=11, run_font_size_pt=[None, None, 8.0], para_first_line_indent=-91440, run_text=['aan  ', 'prn,ind  ', 'DFZH  [an]:Z<->'], run_bold=[True, None, None], para_text='aan  prn,ind  DFZH  [an]:Z<->'))], 'root': [(4, [True], ['A'])], 'lemma': (5, [True, False, False], ['a  ', 'prn,sbj,sf  ', 'DFZH  Z<->'])\n",
    "#    } did not have the key: paragraphs\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 ('.pular_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "923e031a042b0333d984d7caca79dafbd2f9b4aa22c38d0c8e773771fd0f73dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
