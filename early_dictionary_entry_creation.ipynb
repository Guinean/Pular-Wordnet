{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exploration notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- want to -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# altair to visualize the data. read in pickle\n",
    "# determine df shape for this to work\n",
    "# import birdseye and snoop\n",
    "import snoop\n",
    "import altair as alt\n",
    "# from vega_datasets import data\n",
    "from typing import Optional, Dict, List, Any, Union, Tuple\n",
    "import pydantic\n",
    "from pydantic import ValidationError, validator, root_validator, Field, constr, BaseModel\n",
    "from pydantic_docx import Docx_Paragraph_and_Runs, read_docx, extract_features #type:ignore\n",
    "from pydantic_docx_processor import create_sized_dataframe, expand_dataframe #type:ignore\n",
    "import re\n",
    "import json\n",
    "from itertools import compress, chain\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wheat = np.linspace(0,100,53)\n",
    "# # print(wheat)\n",
    "# np.random.seed(42)\n",
    "# year = np.linspace(1800,1900,20)\n",
    "# np.random.shuffle(year)\n",
    "# # print(year)\n",
    "# # print(list(zip(wheat,year)))\n",
    "# source = pd.DataFrame(data=zip(wheat,year),columns = ['wheat','year'])\n",
    "# # df\n",
    "\n",
    "# # source = data.wheat()\n",
    "\n",
    "# bars = alt.Chart(source).mark_bar().encode(\n",
    "#     x='wheat:Q',\n",
    "#     y=\"year:O\"\n",
    "# )\n",
    "\n",
    "# text = bars.mark_text(\n",
    "#    align='left',\n",
    "#    baseline='middle',\n",
    "#    dx=3,  # Nudges text to right so it doesn't appear on top of the bar\n",
    "#    # fontStyle = alt.FontStyle('FlibberGiggets') #Courier New\n",
    "#    font = 'Source Code Pro', #Courier New\n",
    "#    # font = 'Courier New',\n",
    "# ).encode(\n",
    "#     text='wheat:Q'\n",
    "# )\n",
    "\n",
    "# (bars + text).properties(height=900)\n",
    "\n",
    "# rects = alt.Chart(source).mark_rect().encode(\n",
    "#    x = 'run_start', #re.search/find, indent dist?\n",
    "#    x2 = 'run_end', #start plus len\n",
    "#    y = 'const' #dont do wraps, its just too much extra work\n",
    "# )\n",
    "\n",
    "# #assumptions of of other font types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('feature_Frames_and_Indexes.pkl', 'rb') as file:\n",
    "    # Call load method to deserialze\n",
    "    output = pickle.load(file, encoding='utf-8')\n",
    "(\n",
    "parsed_object_list, #:List[Tuple[int,Docx_Paragraph_and_Runs]]\n",
    "parsed_object_lookup, #:Dict[int,Docx_Paragraph_and_Runs] = dict(parsed_object_list)\n",
    "doc_para_count, #: int = int(parsed_to_dict['total_encountered_paragraphs']) #type: ignore\n",
    "char_counts, #: Counter = parsed_to_dict['char_counts'] #type: ignore\n",
    "rootFrame,#:pd.DataFrame\n",
    "rootsubpieceFrame, #:pd.DataFrame\n",
    "lemmaFrame, #:pd.DataFrame\n",
    "nonentityParaFrame, #pd.DataFrame\n",
    "cleanerOutcomesDf #pd.DataFrame\n",
    "    ) = output\n",
    "paratext_lookup = {k:v.interogate__para_text() for k,v in parsed_object_lookup.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_inheritance_frames_tup.pkl', 'rb') as file:\n",
    "    # Call load method to deserialze\n",
    "    output = pickle.load(file, encoding='utf-8')\n",
    "# print(output)\n",
    "(\n",
    "allParagraphsInheritanceFrame,\n",
    "entityDeclarationParas,\n",
    "paragraphRecordsFrame\n",
    ") = output\n",
    "# print(type(allParagraphsInheritanceFrame))\n",
    "all_inheritance_frames_dict = {\n",
    "   'allParagraphsInheritanceFrame':allParagraphsInheritanceFrame,\n",
    "   'entityDeclarationParas':entityDeclarationParas,\n",
    "   'paragraphRecordsFrame':paragraphRecordsFrame\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraphIndex_root</th>\n",
       "      <th>is_root</th>\n",
       "      <th>text_root</th>\n",
       "      <th>mask_root</th>\n",
       "      <th>run_text_list_root</th>\n",
       "      <th>paragraphIndex_root_subpiece</th>\n",
       "      <th>is_root_subpiece</th>\n",
       "      <th>text_root_subpiece</th>\n",
       "      <th>mask_root_subpiece</th>\n",
       "      <th>run_text_list_root_subpiece</th>\n",
       "      <th>paragraphIndex_lemma</th>\n",
       "      <th>is_lemma</th>\n",
       "      <th>text_lemma</th>\n",
       "      <th>mask_lemma</th>\n",
       "      <th>run_text_list_lemma</th>\n",
       "      <th>paragraphIndex</th>\n",
       "      <th>run_text_list_paragraph</th>\n",
       "      <th>run_enumerated_root</th>\n",
       "      <th>run_enumerated_root_subpiece</th>\n",
       "      <th>run_enumerated_lemma</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>a</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[a  , prn,sbj,sf  , DFZH  Z&lt;-&gt;]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[you (sg.)]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>a</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[a  , prn,sbj,sf  , DFZH  Z&lt;-&gt;]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[tu]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>-a</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[-a  , suf,pos  , F]</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[your (sg.) (only with certain nouns such as t...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>-a</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[-a  , suf,pos  , F]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[ton, ta, tes (seulement pour certains substan...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.0</td>\n",
       "      <td>root</td>\n",
       "      <td>A</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>aan</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[aan  , prn,ind  , DFZH  [an]:Z&lt;-&gt;]</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[you (sg.) (emphatic)]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32498</th>\n",
       "      <td>32495.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUW-</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUW-]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32496.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>ƴuuwaade</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuwaade  , v.mv  , D  [ƴuubaade, ƴooraade]]</td>\n",
       "      <td>32498.0</td>\n",
       "      <td>[s'incliner; se cabrer]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32501</th>\n",
       "      <td>32499.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUƳ-</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUƳ-]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>ƴuuƴude</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuƴude  , v.av  , D]</td>\n",
       "      <td>32501.0</td>\n",
       "      <td>[to increase in volume]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32502</th>\n",
       "      <td>32499.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUƳ-</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUƳ-]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>ƴuuƴude</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuƴude  , v.av  , D]</td>\n",
       "      <td>32502.0</td>\n",
       "      <td>[augmenter de volume]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32505</th>\n",
       "      <td>32503.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUƳ-  (2?)</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUƳ-  (2?)]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32504.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>ƴuuƴude</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuƴude  , v.av  , D]</td>\n",
       "      <td>32505.0</td>\n",
       "      <td>[to give (push with?) the head to get out ?; t...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32506</th>\n",
       "      <td>32503.0</td>\n",
       "      <td>root</td>\n",
       "      <td>ƳUUƳ-  (2?)</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[ƳUUƳ-  (2?)]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32504.0</td>\n",
       "      <td>lemma</td>\n",
       "      <td>ƴuuƴude</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[ƴuuƴude  , v.av  , D]</td>\n",
       "      <td>32506.0</td>\n",
       "      <td>[donner (de?) la tête pour sortir; gonfler]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16807 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       paragraphIndex_root is_root    text_root mask_root run_text_list_root  \\\n",
       "index                                                                          \n",
       "6                      4.0    root            A    [True]                [A]   \n",
       "7                      4.0    root            A    [True]                [A]   \n",
       "9                      4.0    root            A    [True]                [A]   \n",
       "10                     4.0    root            A    [True]                [A]   \n",
       "12                     4.0    root            A    [True]                [A]   \n",
       "...                    ...     ...          ...       ...                ...   \n",
       "32498              32495.0    root        ƳUUW-    [True]            [ƳUUW-]   \n",
       "32501              32499.0    root        ƳUUƳ-    [True]            [ƳUUƳ-]   \n",
       "32502              32499.0    root        ƳUUƳ-    [True]            [ƳUUƳ-]   \n",
       "32505              32503.0    root  ƳUUƳ-  (2?)    [True]      [ƳUUƳ-  (2?)]   \n",
       "32506              32503.0    root  ƳUUƳ-  (2?)    [True]      [ƳUUƳ-  (2?)]   \n",
       "\n",
       "       paragraphIndex_root_subpiece is_root_subpiece text_root_subpiece  \\\n",
       "index                                                                     \n",
       "6                               NaN              NaN                NaN   \n",
       "7                               NaN              NaN                NaN   \n",
       "9                               NaN              NaN                NaN   \n",
       "10                              NaN              NaN                NaN   \n",
       "12                              NaN              NaN                NaN   \n",
       "...                             ...              ...                ...   \n",
       "32498                           NaN              NaN                NaN   \n",
       "32501                           NaN              NaN                NaN   \n",
       "32502                           NaN              NaN                NaN   \n",
       "32505                           NaN              NaN                NaN   \n",
       "32506                           NaN              NaN                NaN   \n",
       "\n",
       "      mask_root_subpiece run_text_list_root_subpiece  paragraphIndex_lemma  \\\n",
       "index                                                                        \n",
       "6                    NaN                         NaN                   5.0   \n",
       "7                    NaN                         NaN                   5.0   \n",
       "9                    NaN                         NaN                   8.0   \n",
       "10                   NaN                         NaN                   8.0   \n",
       "12                   NaN                         NaN                  11.0   \n",
       "...                  ...                         ...                   ...   \n",
       "32498                NaN                         NaN               32496.0   \n",
       "32501                NaN                         NaN               32500.0   \n",
       "32502                NaN                         NaN               32500.0   \n",
       "32505                NaN                         NaN               32504.0   \n",
       "32506                NaN                         NaN               32504.0   \n",
       "\n",
       "      is_lemma text_lemma            mask_lemma  \\\n",
       "index                                             \n",
       "6        lemma          a  [True, False, False]   \n",
       "7        lemma          a  [True, False, False]   \n",
       "9        lemma         -a  [True, False, False]   \n",
       "10       lemma         -a  [True, False, False]   \n",
       "12       lemma        aan  [True, False, False]   \n",
       "...        ...        ...                   ...   \n",
       "32498    lemma   ƴuuwaade  [True, False, False]   \n",
       "32501    lemma    ƴuuƴude  [True, False, False]   \n",
       "32502    lemma    ƴuuƴude  [True, False, False]   \n",
       "32505    lemma    ƴuuƴude  [True, False, False]   \n",
       "32506    lemma    ƴuuƴude  [True, False, False]   \n",
       "\n",
       "                                 run_text_list_lemma  paragraphIndex  \\\n",
       "index                                                                  \n",
       "6                    [a  , prn,sbj,sf  , DFZH  Z<->]             6.0   \n",
       "7                    [a  , prn,sbj,sf  , DFZH  Z<->]             7.0   \n",
       "9                               [-a  , suf,pos  , F]             9.0   \n",
       "10                              [-a  , suf,pos  , F]            10.0   \n",
       "12               [aan  , prn,ind  , DFZH  [an]:Z<->]            12.0   \n",
       "...                                              ...             ...   \n",
       "32498  [ƴuuwaade  , v.mv  , D  [ƴuubaade, ƴooraade]]         32498.0   \n",
       "32501                         [ƴuuƴude  , v.av  , D]         32501.0   \n",
       "32502                         [ƴuuƴude  , v.av  , D]         32502.0   \n",
       "32505                         [ƴuuƴude  , v.av  , D]         32505.0   \n",
       "32506                         [ƴuuƴude  , v.av  , D]         32506.0   \n",
       "\n",
       "                                 run_text_list_paragraph run_enumerated_root  \\\n",
       "index                                                                          \n",
       "6                                            [you (sg.)]                 [0]   \n",
       "7                                                   [tu]                 [0]   \n",
       "9      [your (sg.) (only with certain nouns such as t...                 [0]   \n",
       "10     [ton, ta, tes (seulement pour certains substan...                 [0]   \n",
       "12                                [you (sg.) (emphatic)]                 [0]   \n",
       "...                                                  ...                 ...   \n",
       "32498                            [s'incliner; se cabrer]                 [0]   \n",
       "32501                            [to increase in volume]                 [0]   \n",
       "32502                              [augmenter de volume]                 [0]   \n",
       "32505  [to give (push with?) the head to get out ?; t...                 [0]   \n",
       "32506        [donner (de?) la tête pour sortir; gonfler]                 [0]   \n",
       "\n",
       "      run_enumerated_root_subpiece run_enumerated_lemma  \n",
       "index                                                    \n",
       "6                              NaN            [0, 1, 2]  \n",
       "7                              NaN            [0, 1, 2]  \n",
       "9                              NaN            [0, 1, 2]  \n",
       "10                             NaN            [0, 1, 2]  \n",
       "12                             NaN            [0, 1, 2]  \n",
       "...                            ...                  ...  \n",
       "32498                          NaN            [0, 1, 2]  \n",
       "32501                          NaN            [0, 1, 2]  \n",
       "32502                          NaN            [0, 1, 2]  \n",
       "32505                          NaN            [0, 1, 2]  \n",
       "32506                          NaN            [0, 1, 2]  \n",
       "\n",
       "[16807 rows x 20 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphRecordsFrame\n",
    "# entityDeclarationParas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_any_entity                                              lemma\n",
       "is_any_root                                                 root\n",
       "is_main_root                                                root\n",
       "lemma_run_numbers                                            NaN\n",
       "mask_any_entity                             [True, False, False]\n",
       "mask_any_root                                             [True]\n",
       "mask_main_root                                            [True]\n",
       "paragraphIndex_any_entity                                   11.0\n",
       "paragraphIndex_any_root                                      4.0\n",
       "paragraphIndex_main_root                                     4.0\n",
       "run_text_list_any_entity     [aan  , prn,ind  , DFZH  [an]:Z<->]\n",
       "run_text_list_any_root                                       [A]\n",
       "run_text_list_main_root                                      [A]\n",
       "text_any_entity                                              aan\n",
       "text_any_root                                                  A\n",
       "text_main_root                                                 A\n",
       "paragraphIndex                                               NaN\n",
       "Name: 11, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entityDeclarationParas.loc[11,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7994\n",
      "7985\n"
     ]
    }
   ],
   "source": [
    "workinglemmas = paragraphRecordsFrame.groupby(['paragraphIndex_root','paragraphIndex_root_subpiece','paragraphIndex_lemma'])\n",
    "print(len(workinglemmas))\n",
    "workinglemmas = {k:list(v) for k,v in workinglemmas.groups.items() if len(v) >=2}\n",
    "print(len(workinglemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((4.0, nan, 5.0), [6, 7]),\n",
       " ((4.0, nan, 8.0), [9, 10]),\n",
       " ((4.0, nan, 11.0), [12, 13]),\n",
       " ((4.0, nan, 14.0), [15, 16]),\n",
       " ((4.0, nan, 17.0), [18, 19])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(workinglemmas.items()))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAssert(dct,val,typ:type, strict = True) -> Any:\n",
    "   out = dct.get(val,None)\n",
    "   if strict and typ is type(None):\n",
    "      raise NotImplementedError(f'this get/assert function cannot \"get\" None values safely, and a {val} type was passed for dict {dict}')\n",
    "   if strict and out is None:\n",
    "      raise KeyError(f\"the provided dict {dct} did not have the key: {val}\")\n",
    "   assert isinstance(out,typ), f\"the provided dict {dct} did not give {val} with the expected type: {typ}, but instead {out}\"\n",
    "   return out\n",
    "   \n",
    "def trustyGet(obj:Docx_Paragraph_and_Runs, feat: str, silent_return = True) -> str:\n",
    "      if not silent_return:\n",
    "         output : str = getattr(obj,feat,'')\n",
    "         if len(output) > 0:\n",
    "            return output\n",
    "         else:\n",
    "            raise AttributeError(f'trusty getter could not find: {feat}')\n",
    "      else:\n",
    "         output : str = getattr(obj,feat,'')\n",
    "         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dict_entry(pydantic.BaseModel): \n",
    "   '''\n",
    "   #True is used as default value, and must be changed to False if the feature is not found. This will catch not implemented, and incomplete updates\n",
    "   '''\n",
    "   irregularities: List[str] = []\n",
    "   lemma_index: int \n",
    "   \n",
    "   lemma: str = Field(...,min_length = 1) #article\n",
    "   root: str\n",
    "   root_subpiece: Union[str,bool] = True #these will not be updated after initialization\n",
    "   root_metadata: Dict[str,Any]  #index,root_text, root_meta_data #article \n",
    "   root_origin: Union[str,bool] = True #these will not be updated after initialization\n",
    "   #Paragraph Derivatives: Glosses and Annotations\n",
    "   lemmaLine_runs: List[str] #these will not be updated after initialization\n",
    "   englishGlossLine_runs: Union[List[str],bool] = True #these will not be updated after initialization\n",
    "   frenchGlossLine_runs: Union[List[str],bool] = True #these will not be updated after initialization\n",
    "   FulaAnnotations_runs: Union[List[List[str]],bool]= True #these will not be updated after initialization\n",
    "\n",
    "   #Gloss Derivatives: English Senses\n",
    "   FulaSenseEnglish: Union[List[str],bool] = True #list of \"senses\" split by semicolons #article\n",
    "   FulaSenseEnglish_Count: Union[int,bool] = True #number of senses in english #aka FulaSenseClassifications #article\n",
    "   FulaSenseEnglish_Annotations: Union[List[str],bool] = True #contains the annotations (in parenthesis) for a given sense, if any #article \n",
    "   FulaSenseEnglish_Synonyms: Union[List[str],bool] = True #holds bracket text for a sense, suspected all synonyms. These may all occur at the end, and may be redundant with the synonyms provided at the head of the entry\n",
    "   FulaSenseEnglish_unusedContent: Union[List[str],bool] = True #holds any run text that is not contained in the above features\n",
    "   \n",
    "   #Gloss Derivatives: French Senses\n",
    "   FulaSenseFrench: Union[List[str],bool] = True #article\n",
    "   FulaSenseFrench_Count: Union[int,bool] = True #aka FulaSenseClassifications\n",
    "   FulaSenseFrench_Annotations: Union[List[str],bool] = True\n",
    "   FulaSenseFrench_Synonyms: Union[List[str],bool] = True\n",
    "   FulaSenseFrench_unusedContent: Union[List[str],bool] = True\n",
    "   \n",
    "   #lemma derivative\n",
    "   lemmaLine_unusedContent: List[Tuple[int,str]] #= Field(...) #int is index for run to allow tracing as entries are removed\n",
    "   FulaDialects: Union[List[str],bool] = True #article\n",
    "   FulaPOSTags: Union[List[str],bool] = True #article\n",
    "   FulaPOSClass: Union[List[str],bool] = True #Noun, Adj, Verb, Adv, Prn, ..., Complicated, Indeterminate\n",
    "   FulaNoun_NounsAndClass: Union[List[Tuple[str,str]],bool] = True #Pular has unique noun classes. Lemma will be copied here beside its class (\"noun\", \"nounclass\"), and any additional singular forms will be in additional tuples in this same list\n",
    "   FulaNoun_PluralsAndClass: Union[List[str],bool] = True #temporary measure #TODO. include list of wordclasses find all and not '/' findall #Union[List[Tuple[str,str]],bool] = True #Dict provides plurals for nouns. Tuples will have (\"noun\", \"nounclass\")\n",
    "   FulaSynonyms: Union[List[str],bool] = True #article\n",
    "   FulaCrossRef: Union[List[str],bool] = True\n",
    "         # FulaVerbClass:\n",
    "   #paras\n",
    "   paragraphs: List[Docx_Paragraph_and_Runs] = Field(...,min_items = 1)\n",
    "   \n",
    "   class Config:\n",
    "      validate_all = True\n",
    "      # validate_assignment = True\n",
    "      smart_union = True  \n",
    "      extra = 'forbid'\n",
    "\n",
    "   @root_validator(pre=True)\n",
    "   def _validate_and_build(cls, values: Dict[str,Any]) -> Dict[str, Any]:\n",
    "      # print(values)\n",
    "      newValues: Dict[str,Any] = {}\n",
    "      newValues['irregularities'] = []\n",
    "\n",
    "      ###PARAGRAPHS CHECK###\n",
    "      # print(values)\n",
    "      newValues['paragraphs'] = getAssert(values,'paragraphs',list) #these come in as tuples(ind,para)\n",
    "      #TODO have more rigorous checks on para since so much depends on that even in this validation\n",
    "      assert isinstance(newValues['paragraphs'][0],tuple), 'currently paras must be packaged in a tuple with their original doc index'\n",
    "      newValues['paragraphs'] = [p for i,p in newValues['paragraphs']]\n",
    "      if len(newValues['paragraphs']) == 0:\n",
    "         raise ValueError('given invalid paragraphs of zero length')\n",
    "      else: #logic for subsidary paragraphs\n",
    "         lemma_line = trustyGet(newValues['paragraphs'][0],feat = 'run_text', silent_return=False)\n",
    "         newValues['lemmaLine_runs'] = lemma_line\n",
    "         if len(newValues['paragraphs']) <3:\n",
    "            raise ValueError('incorrect number of paragraphs provided')\n",
    "         elif len(newValues['paragraphs']) == 3:\n",
    "            newValues['englishGlossLine_runs'] = newValues['paragraphs'][1].get_run_text()\n",
    "            newValues['frenchGlossLine_runs'] = newValues['paragraphs'][2].get_run_text()\n",
    "         else: \n",
    "            newValues['englishGlossLine_runs'] = newValues['paragraphs'][1].get_run_text()\n",
    "            newValues['frenchGlossLine_runs'] = newValues['paragraphs'][2].get_run_text()\n",
    "            newValues['FulaAnnotations_runs'] = []\n",
    "            for p in newValues['paragraphs'][3:]:\n",
    "               # print(p.get_run_text())\n",
    "               newValues['FulaAnnotations_runs'].append(p.get_run_text())\n",
    "      \n",
    "      \n",
    "      try: ###LEMMA CHECK###\n",
    "         #reading in lemma results from first pass of pydantic parser\n",
    "         lemma_index, lemma_mask, lemmaLine_runs = getAssert(values,'lemma',tuple)\n",
    "         #checking for correct structure\n",
    "         lemma_matched_runs = list(compress(lemmaLine_runs,lemma_mask))\n",
    "         if len(lemma_matched_runs) > 1:\n",
    "            newValues['irregularities'].append('What:Unexpected, Where: Lemmas, Why: the merge routines should aggregate adjacent runs with same features. Multiple Lemma runs should not be possible if Bold is contiguous')\n",
    "         lemma_text = ''.join(chain(lemma_matched_runs)).strip()\n",
    "            #TODO have better control for expected structure that these runs should be adjacent (and only should be one)\n",
    "         #saving values. These will have to pass type check of declared attribute types for validation to succeed\n",
    "         newValues['lemma'] = lemma_text\n",
    "         newValues['lemma_index'] = lemma_index\n",
    "         newValues['lemmaLine_runs'] = lemmaLine_runs\n",
    "         # first_lemma = False\n",
    "         used_run_mask = [False]*len(lemma_mask)\n",
    "         for i,b in enumerate(lemma_mask):\n",
    "            if b:\n",
    "               used_run_mask[i]=True\n",
    "         # used_run_mask = lemma_mask\n",
    "\n",
    "      except Exception as e:\n",
    "         #exception lemma check\n",
    "         raise RuntimeError('failed lemma check') from e\n",
    "\n",
    "      try: ###ROOT CHECK###\n",
    "         #reading in root results from first pass of pydantic parser\n",
    "         #checking for correct structure\n",
    "         root_index, root_mask, rootLine_runs = getAssert(values,'root',tuple)\n",
    "         root_matched_runs = list(compress(rootLine_runs,root_mask))\n",
    "         if len(root_matched_runs) > 1:\n",
    "            newValues['irregularities'].append('What:Unexpected, Where: Root, Why: the merge routines should aggregate adjacent runs with same features. Multiple Root runs should not be possible if Fontsize is contiguous and unique')\n",
    "         root_text = ''.join(chain(root_matched_runs)).strip()\n",
    "         if root_index == newValues['lemma_index']:\n",
    "            newValues['irregularities'].append('What:inconsistent, Where: Lemmas and Root, Why:normally root and lemma are on different lines. This has them sharing, which may indicate a lack of other content')\n",
    "            used_run_mask = [any(run) for run in list(zip(used_run_mask,root_mask))]\n",
    "            rootLine_runs = False\n",
    "         newValues['root'] = root_text\n",
    "         newValues['root_metadata'] = {'root_index': root_index, 'root_runs':rootLine_runs}\n",
    "      except Exception as e:\n",
    "         #exception ROOT check\n",
    "         raise RuntimeError('failed ROOT check') from e\n",
    "\n",
    "      try: ###ROOT-Subpiece CHECK###\n",
    "         #iterating in case a subroot is present\n",
    "         root_index, root_mask, rootLine_runs = getAssert(values,'root_subpiece',tuple)\n",
    "         root_matched_runs = list(compress(rootLine_runs,root_mask))\n",
    "         if len(root_matched_runs) > 1:\n",
    "            newValues['irregularities'].append('What:Unexpected, Where: Root-Subpiece, Why: the merge routines should aggregate adjacent runs with same features. Multiple Root runs should not be possible if Fontsize is contiguous and unique')\n",
    "         root_subpiece_text = ''.join(chain(root_matched_runs)).strip()\n",
    "         if root_index == newValues['lemma_index']:\n",
    "            newValues['irregularities'].append('What:inconsistent, Where: Lemmas and Root-Subpiece, Why:normally root and lemma are on different lines. This has them sharing, which may indicate a lack of other content')\n",
    "            used_run_mask = [any(run) for run in list(zip(used_run_mask,root_mask))]\n",
    "            rootLine_runs = False\n",
    "         newValues['root_subpiece'] = root_subpiece_text\n",
    "         newValues['root_metadata'] = {'root_subpiece_index': root_index, 'root_subpiece_runs':rootLine_runs}\n",
    "      except AssertionError as e:\n",
    "         newValues['root_subpiece'] = False\n",
    "      except Exception as e:\n",
    "         #exception ROOT-Subpiece check\n",
    "         raise RuntimeError('failed ROOT-Subpiece check') from e\n",
    "\n",
    "      #determining lemmaLine_unusedContent\n",
    "      unused_run_mask = [not r for r in used_run_mask]\n",
    "      # print(unused_run_mask)\n",
    "      # print(list(compress(enumerate(newValues['lemmaLine_runs']),unused_run_mask)))\n",
    "      newValues['lemmaLine_unusedContent'] = list(compress(enumerate(newValues['lemmaLine_runs']),unused_run_mask))\n",
    "      \n",
    "      return newValues\n",
    "\n",
    "   def parse_senses(self):\n",
    "      #TODO\n",
    "      return\n",
    "\n",
    "   def parse_glossRemainder(self):\n",
    "      #TODO\n",
    "      return\n",
    "\n",
    "   def parse_lemmaLine(self):\n",
    "      \n",
    "      pos_config = {'docxFeature': 'run_italic',\n",
    "               'strSummary':'fontItalic', \n",
    "               'value':True}\n",
    "      (is_target, text, target_mask, run_text) = extract_features(self.paragraphs[0],pos_config)\n",
    "      #POS\n",
    "      if is_target:\n",
    "         for i,b in enumerate(target_mask):\n",
    "            if b:\n",
    "               text = run_text[i] #TODO this only pulls POS info from the first contiguous italics run\n",
    "               # print(text)\n",
    "         #noun\n",
    "            #regex () to remove FulaWordClass\n",
    "            #regex / to get plural\n",
    "            # regex n.\n",
    "         word_class = re.findall(r\"\\(([^\\)]+)\\)\",text) #anything between parenthesis\n",
    "         # print(word_class)\n",
    "         noun_flag = re.findall(r\"(n\\.)\",text)\n",
    "         plurals = re.findall(r\"([^\\/]+)\",text) #anything not a /\n",
    "         if any([len(word_class)>0, noun_flag, len(plurals)>1]):\n",
    "            # print('here')\n",
    "            is_noun = True\n",
    "            self.FulaPOSClass = ['Noun']\n",
    "            if word_class:\n",
    "               self.FulaNoun_NounsAndClass = [(self.lemma,word_class[0])]\n",
    "            if len(plurals)>1:\n",
    "               # self.FulaNoun_NounsAndClass\n",
    "               if len(plurals)>2:\n",
    "                  print(self.lemma_index,' - index lemma has multiple noun slashes \"/\"')\n",
    "               # plurals_word_class = re.findall(\"\\(([^\\)]+)\\)\",plurals[1])  #anything between parenthesis\n",
    "               # plurals_text = re.findall(\"(?<![^\\)])[^\\(]+(?![^\\(]*\\))\",plurals[1]) #anything NOT between ()\n",
    "               self.FulaNoun_PluralsAndClass = plurals #TODO\n",
    "            else:\n",
    "               pass\n",
    "         else:\n",
    "            self.FulaNoun_NounsAndClass = False\n",
    "            is_verb = bool(re.findall(r\"v.\",text.lower()))\n",
    "            if is_verb:\n",
    "               self.FulaPOSClass = ['Verb']\n",
    "            self.FulaPOSTags = text.replace('+',',').split(',')\n",
    "\n",
    "      #dialect\n",
    "      dialects = []\n",
    "      for run in self.lemmaLine_runs:\n",
    "         dialects.extend(re.findall(r\"\\<([^\\>]+)\\>\",run)) #anything between parenthesis\n",
    "      if len(dialects)>0:\n",
    "         self.FulaDialects = list(set(dialects))\n",
    "      else:\n",
    "         self.FulaDialects = 'Mali'\n",
    "      #cross ref\n",
    "         # cross_reference = r\"cf\\.\\:(.+)|cf\\:(.+)\" #TODO\n",
    "      #syn\n",
    "         #TODO\n",
    "\n",
    "      \n",
    "      return\n",
    "\n",
    "   def parse_lemmaLineRemainder(self):\n",
    "      #TODO\n",
    "      return\n",
    "\n",
    "   def get_rootOrigin(self):\n",
    "      #TODO\n",
    "      return\n",
    " \n",
    "   def give_entryText(self, joiner = '\\t') -> str: #article\n",
    "      return joiner.join([para.trustyGet('para_text') for para in self.paragraphs])\n",
    "\n",
    "   \n",
    "      \n",
    "            \n",
    "# dict_entry.parse_obj({'paragraphs':[b for a,b in parsed_object_list[5:8]]})\n",
    "\n",
    "# incoming = {\n",
    "#    'paragraphs': List[Docx_Paragraph_and_Runs],\n",
    "#    'root': List[int,str,List[bool]],\n",
    "#    'lemma': List[int,str,List[bool]],\n",
    "#    # 'pos': \n",
    "# }\n",
    "\n",
    "# [\n",
    "#    ['paras'], #obj\n",
    "#    ['parsed_paras'], #pydocx\n",
    "#    ['roots'], #name, fill forwards\n",
    "#    ['lemmas']  #text, fill forwards\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = 'sdalje (djg) ,shkg / (w+sjh) skodhf'\n",
    "# word_class = re.findall(\"(?<![^\\)])[^\\(]+(?![^\\(]*\\))\",text)\n",
    "# word_class\n",
    "# text.replace('+',',').split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Fula_Entry (BaseModel): \n",
    "#    entity_word: List[str] #root, subroot, lemma\n",
    "#    features: Optional[Dict[str,str]] = {} #contains features for this entity, ie: txt file features like location, POS, etc. Only applicable directly. Lemmas have POS, roots do not, etc\n",
    "#    paragraphs_list: Dict[int,Any] #para enumeration, docx para obj\n",
    "#    paragraphs_extr : List[Docx_Paragraph_and_Runs] #class defined above\n",
    "#    sub_roots : List['Fula_Entry'] = [] #self reference\n",
    "#    lemmas : List['Fula_Entry'] = [] #self reference\n",
    "all_entries = []\n",
    "for e in workinglemmas.items():\n",
    "   values = {}\n",
    "   root,root_subpiece,lemma = e[0]\n",
    "   paras = e[1]\n",
    "   # parsed_object_lookup[root]\n",
    "   values['paragraphs']= [int(lemma)]+paras\n",
    "   values['paragraphs'] = [(i,parsed_object_lookup[i]) for i in values['paragraphs']]\n",
    "   # print(len(values['paragraphs']))\n",
    "   lemma_mask = entityDeclarationParas.loc[int(lemma),:]['mask_any_entity']\n",
    "   lemmaLine_runs = entityDeclarationParas.loc[int(lemma),:]['run_text_list_any_entity']\n",
    "   values['lemma'] = (int(lemma),lemma_mask,lemmaLine_runs)\n",
    "   root_mask = entityDeclarationParas.loc[int(root),:]['mask_any_entity']\n",
    "   rootLine_runs = entityDeclarationParas.loc[int(root),:]['run_text_list_any_entity']\n",
    "   values['root'] = (int(root),root_mask,rootLine_runs)\n",
    "   if not np.isnan(root_subpiece):\n",
    "      root_subpiece_mask = entityDeclarationParas.loc[int(root_subpiece),:]['mask_any_entity']\n",
    "      root_subpieceLine_runs = entityDeclarationParas.loc[int(root_subpiece),:]['run_text_list_any_entity']\n",
    "      values['root_subpiece'] = (int(root_subpiece),root_subpiece_mask,root_subpieceLine_runs)\n",
    "   else:\n",
    "      values['root_subpiece'] = False\n",
    "   # print(values.get('paragraphs'))\n",
    "   this_entry = dict_entry(**values)\n",
    "   # print('here')\n",
    "   # print(this_entry.json(indent=3))\n",
    "   this_entry.parse_lemmaLine()\n",
    "   all_entries.append(this_entry)\n",
    "\n",
    "   # if len(all_entries)>40:\n",
    "      # break\n",
    "   # break\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_entries = []\n",
    "for e in all_entries:\n",
    "   if e.FulaPOSClass == ['Noun']:\n",
    "      # print(e)\n",
    "      noun_entries.append(e)\n",
    "\n",
    "verb_entries = []\n",
    "for e in all_entries:\n",
    "   if e.FulaPOSClass == ['Verb']:\n",
    "      # print(e)\n",
    "      verb_entries.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4879\n",
      "2672\n",
      "434\n"
     ]
    }
   ],
   "source": [
    "print(len(noun_entries))\n",
    "print(len(verb_entries))\n",
    "print(len(all_entries)-len(verb_entries)-len(noun_entries))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 ('.pular_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "923e031a042b0333d984d7caca79dafbd2f9b4aa22c38d0c8e773771fd0f73dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
