{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intention = '''Create an easy/safe API to parse/hold/yield constructions of pydantic docx class objects.\n",
    "In theory this can be generalized and abstracted since the classes are largely absracted. \n",
    "However since this is API based, I will just focus on solutions for THIS dictionary task. These can be expanded later, or just have other APIs added\n",
    "Final objective is have a tool to pass complex commands/instructions, and have it yield a pandas dataframe of the results.\n",
    "Intermediate steps may be yield a list of lists\n",
    "I am not yet sure if there is benefit trying to have the whole dictionary in one notional object. \n",
    "I don't think so, since each operation is psuedo atomic, and any aggregate actions are intended to be done in something like pandas.\n",
    "Eventually I would want a loop for pandas operations to easily feed updates to the data. \n",
    "'''\n",
    "conclusion = '''create a pular dictionary specifc datastructure to handle the aggregate paragraphs. \n",
    "This will only be per lemma, \n",
    "as any aggregations from roots and relations of that sort can be managed in pandas and created by simple inheretance/reference\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, List, Any, Union, Tuple\n",
    "import pydantic\n",
    "from pydantic import ValidationError, validator, root_validator, Field, constr\n",
    "from pydantic_docx import Docx_Paragraph_and_Runs #type:ignore\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = ['txt_FulaAnnotations','txt_FulaLemmas','txt_FulaRoots',\n",
    "'txt_FulaSenseEnglish','txt_FulaSenseFrench',\n",
    "'txt_FulaSenseClassifications',\n",
    "'txt_FulaSenseEnglishAnnotations','txt_FulaSenseFrenchAnnotations',\n",
    "'txt_FulaDialects','txt_FulaPOSTags','txt_FulaSynonyms',\n",
    "'txt_FulaInParenthesis','txt_POS','txt_RootOrigins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Docx_Paragraph_and_Runs', 'description': \"input:   paragraph = your_paragraph_here\\n\\nwhen given a docx document's paragraph object, will parse it to a specified schema\", 'type': 'object', 'properties': {}}\n"
     ]
    }
   ],
   "source": [
    "noun_patterns = [r'n\\.',r\"(?<=\\()[^\\)]+\",r\"\\/\"]\n",
    "nounPatternRegex = re.compile('|'.join([p for p in noun_patterns]))\n",
    "print(nounPatternRegex)\n",
    "s = 'n. dfhjkgqh (wsh) askldjhf / asdfhjkkh'\n",
    "print(re.findall(nounPatternRegex,s))\n",
    "print(nounPatternRegex.findall(s))\n",
    "\n",
    "# if /, the next word is a plural. The plural also then usually has a (el) class after it. commas are multiple version\n",
    "# so each lemma noun may have a (class). The lemma may have one or multiple plurals, which will have a modified (class)\n",
    "# so have a nouns list? nouns may then be \n",
    "# [('n.',{bool}), #only needed if this gets added to all POS? Or maybe theres information in its use?\n",
    "# ([[{word}],{Optional[class]}]),  #singular\n",
    "   #([[{word}],{Optional[class]}])]   #plural\n",
    "\n",
    "# so nounStruct[0][1] is the flag for noun?\n",
    "   # one POS table, and noun will get added there. But the presence of a noun indicates to look here\n",
    "# classes may be found [sClass[1] for sClass in nounStruct[1]] will give all classes of singular, [sClass[1] for sClass in nounStruct[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAssert(dct,val,typ):\n",
    "   out = dct.get(val,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dict_entry(pydantic.BaseModel):\n",
    "   irregularities: List[str]\n",
    "   paragraphs: List[Docx_Paragraph_and_Runs]\n",
    "   lemma: str\n",
    "   root: List[Tuple[int,str,str]] #index,root_text, root_meta_data\n",
    "   englishGloss: str\n",
    "   frenchGloss: str\n",
    "\n",
    "   class Config:\n",
    "      validate_all = True\n",
    "      # extra = 'forbid'\n",
    "      validate_assignment = True\n",
    "      smart_union = True  \n",
    "\n",
    "   @root_validator(pre=True)\n",
    "   def _validate_and_build(cls, values: Dict[str,Any]) -> Dict[str, Any]:\n",
    "\n",
    "\n",
    "   def give_entryText(self, joiner = '\\t') -> str:\n",
    "      return joiner.join([para.trustyGet('para_text') for para in self.paragraphs])\n",
    "\n",
    "   def give_root_text(self, main = False, sub = False, both = True) -> str:\n",
    "      if both:\n",
    "         return ''.join([r[1] for r in self.root])\n",
    "      if main:\n",
    "         return  str(self.root[0][1])\n",
    "      if sub:\n",
    "         return str(self.root[1][1])\n",
    "      raise RuntimeError('did not give valid input')\n",
    "\n",
    "   def trustyGet(self, feat: str, silent_return = True) -> str:\n",
    "      if not silent_return:\n",
    "         output : str = getattr(self,feat,'')\n",
    "         if output:\n",
    "            return output\n",
    "         else:\n",
    "            raise AttributeError(f'trusty getter could not find: {feat}')\n",
    "      else:\n",
    "         output : str = getattr(self,feat,'')\n",
    "         return output\n",
    "      \n",
    "def getAssert(dct,val,typ):\n",
    "   out = dct.get(val,False)\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 ('.pular_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "923e031a042b0333d984d7caca79dafbd2f9b4aa22c38d0c8e773771fd0f73dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
